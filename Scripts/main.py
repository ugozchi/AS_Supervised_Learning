import polars as pl
import pandas as pd
import numpy as np
import xgboost as xgb
import time
from sklearn.model_selection import KFold, cross_val_score, train_test_split
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import GradientBoostingRegressor
from sklearn.metrics import mean_squared_error, mean_absolute_error, make_scorer

# --- 0. D√âFINITION GLOBALE DES FONCTIONS ROBUSTES ---

# Chemin d'acc√®s au fichier ML (ajuster si n√©cessaire)
FILE_PATH_ML = "Data/processed/sirene_bilan_ML_prets.parquet" 
cible_col = "cible_HN_R√©sultatNet_T_plus_1"

# Fonction de transformation robuste de la cible (ARCSINH)
def arcsinh_transform_safe(y):
    # Transformation recommand√©e pour les donn√©es financi√®res (gains et pertes)
    # Ajout d'epsilon pour la robustesse pr√®s de z√©ro
    return np.arcsinh(y + np.finfo(float).eps)

# Fonction d'inverse transformation
def inv_arcsinh_transform_safe(y_pred_arcsinh):
    # Inverse de arcsinh
    return np.sinh(y_pred_arcsinh) - np.finfo(float).eps

# Scoreurs pour la Cross-Validation
def root_mean_squared_error(y_true, y_pred):
    # Fonction RMSE avec conversion pour √©viter l'overflow
    return np.sqrt(mean_squared_error(y_true.astype(np.float64), y_pred.astype(np.float64)))

scorer_mae = make_scorer(mean_absolute_error, greater_is_better=False)
scorer_rmse = make_scorer(root_mean_squared_error, greater_is_better=False)

# Features finales retenues pour le mod√®le performant
FEATURES_FINALES = [
    'ratio_rentabilite_nette', 'ratio_endettement', 'ratio_marge_brute', 
    'HN_R√©sultatNet', 'FA_ChiffreAffairesVentes', 
    'delta_ResultatNet_1an', 'delta_CA_1an', 'ResultatNet_T_moins_1', 'CA_T_moins_1'
]


# --- CLASSE PRINCIPALE D'ENTRA√éNEMENT ---
class FinalModelTrainer:
    
    def __init__(self):
        self.kf = KFold(n_splits=5, shuffle=True, random_state=42)
        
    def load_and_prepare_data(self):
        """Charge, nettoie et transforme les donn√©es."""
        print("Chargement et pr√©paration des donn√©es...")
        try:
            df_ml = pl.read_parquet(FILE_PATH_ML)
        except Exception:
            raise RuntimeError("Erreur de chargement du fichier Parquet.")

        df_ml_pd = df_ml.to_pandas()
        
        # Application de la transformation ARCSINH √† la Cible (Y)
        Y_full_arcsinh = arcsinh_transform_safe(df_ml_pd[cible_col].astype(np.float64))

        # Pr√©paration des Features X
        X_full = df_ml_pd[FEATURES_FINALES].fillna(0).astype(np.float64) 
        
        print(f"Jeu de donn√©es pr√™t : {X_full.shape[0]} observations.")
        return X_full, Y_full_arcsinh

    def build_and_evaluate_pipeline(self, X, Y):
        """Construit le pipeline (Gradient Boosting) et √©value par CV."""
        print("\nConstruction du pipeline Gradient Boosting (Mod√®le Monstre)...")
        
        # Pre-processing (StandardScaler)
        preprocessor = ColumnTransformer(
            transformers=[('num', StandardScaler(), FEATURES_FINALES)],
            remainder='passthrough'
        )

        # Mod√®le Gradient Boosting (similaire √† XGBoost mais utilise scikit-learn)
        # Ces param√®tres sont choisis pour la robustesse et la performance.
        model_gbr = GradientBoostingRegressor(
            n_estimators=500,  # Nombre d'arbres √©lev√©
            learning_rate=0.05,
            max_depth=5,
            subsample=0.7,
            random_state=42
        )

        pipeline = Pipeline(steps=[
            ('preprocessor', preprocessor),
            ('regressor', model_gbr)
        ])
        
        # --- √âvaluation par Cross-Validation (CV) ---
        print("√âvaluation par 5-Fold Cross-Validation...")
        start_time = time.time()
        
        rmse_scores = cross_val_score(pipeline, X, Y, scoring=scorer_rmse, cv=self.kf, n_jobs=-1)
        mae_scores = cross_val_score(pipeline, X, Y, scoring=scorer_mae, cv=self.kf, n_jobs=-1)
        
        training_time = time.time() - start_time
        
        # Calcul des moyennes (multipli√© par -1 car les scoreurs sont n√©gatifs)
        rmse_cv_mean = np.mean(rmse_scores) * -1
        mae_cv_mean = np.mean(mae_scores) * -1
        
        return pipeline, mae_cv_mean, rmse_cv_mean, training_time

    def inverse_transform_and_evaluate(self, pipeline, X_full, Y_full_arcsinh, final_mae_cv, final_rmse_cv, training_time):
        """Inverse la transformation et affiche les r√©sultats finaux."""
        
        # Entra√Æner le mod√®le final sur toutes les donn√©es avant la pr√©diction
        pipeline.fit(X_full, Y_full_arcsinh)

        # Pr√©diction (Arcsih-transform√©e)
        Y_pred_arcsinh = pipeline.predict(X_full)

        # Inverse Transformation : Retour aux unit√©s mon√©taires originales
        Y_pred_final_unscaled = inv_arcsinh_transform_safe(Y_pred_arcsinh)
        Y_true_unscaled = inv_arcsinh_transform_safe(Y_full_arcsinh)

        # Affichage des m√©triques sur les valeurs R√âELLES
        final_mae_unscaled = mean_absolute_error(Y_true_unscaled, Y_pred_final_unscaled)
        final_rmse_unscaled = root_mean_squared_error(Y_true_unscaled, Y_pred_final_unscaled)

        print("\n=============================================")
        print("üèÜ MOD√àLE MONSTRE FINAL (Gradient Boosting) üèÜ")
        print("=============================================")
        print(f"TEMPS TOTAL D'ENTRA√éNEMENT CV : {training_time:.2f} secondes")
        print(f"Features utilis√©es : Top {len(FEATURES_FINALES)} (Valid√©es par EDA)")
        print("-" * 45)
        print(f"  > MAE (Erreur Absolue Moyenne, Unscaled) : {final_mae_unscaled:,.2f}")
        print(f"  > RMSE (Racine de l'Erreur Quadratique, Unscaled) : {final_rmse_unscaled:,.2f}")
        print(f"  > MAE (Moyenne CV, Interne) : {final_mae_cv:,.2f} (Confirm√© par CV)")
        print("=============================================")


# --- EX√âCUTION DU PIPELINE COMPLET ---
if __name__ == "__main__":
    trainer = FinalModelTrainer()
    
    # 1. Chargement et Transformation
    X_full, Y_full_arcsinh = trainer.load_and_prepare_data()
    
    # 2. Construction et √âvaluation du Pipeline
    pipeline_final, mae_cv, rmse_cv, training_time = trainer.build_and_evaluate_pipeline(X_full, Y_full_arcsinh)
    
    # 3. Affichage des r√©sultats finaux (avec inverse transformation)
    trainer.inverse_transform_and_evaluate(pipeline_final, X_full, Y_full_arcsinh, mae_cv, rmse_cv, training_time)