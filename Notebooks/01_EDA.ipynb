{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA Demographique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- DÃ©but de la lecture 'bypass' ---\n",
      "Lecture du fichier via PyArrow : ../Data/processed/sirene_infos.parquet\n",
      "Conversion de la table PyArrow en DataFrame Polars...\n",
      "--- SUCCÃˆS ! ---\n",
      "\n",
      "Le DataFrame est maintenant dans Polars, prÃªt pour la transformation.\n",
      "shape: (5, 15)\n",
      "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
      "â”‚ siren     â”† dateCreat â”† dateFerme â”† is_failed â”† â€¦ â”† moisCreat â”† departeme â”† trancheEf â”† caracter â”‚\n",
      "â”‚ ---       â”† ionUniteL â”† ture      â”† _in_3y    â”†   â”† ion       â”† nt        â”† fectifsSi â”† eEmploye â”‚\n",
      "â”‚ str       â”† egale     â”† ---       â”† ---       â”†   â”† ---       â”† ---       â”† ege       â”† urSiege  â”‚\n",
      "â”‚           â”† ---       â”† date      â”† i32       â”†   â”† i8        â”† str       â”† ---       â”† ---      â”‚\n",
      "â”‚           â”† date      â”†           â”†           â”†   â”†           â”†           â”† str       â”† str      â”‚\n",
      "â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•¡\n",
      "â”‚ 000325175 â”† 2000-09-2 â”† null      â”† 0         â”† â€¦ â”† 9         â”† 13        â”† NN        â”† N        â”‚\n",
      "â”‚           â”† 6         â”†           â”†           â”†   â”†           â”†           â”†           â”†          â”‚\n",
      "â”‚ 005540273 â”† 1972-01-0 â”† null      â”† 0         â”† â€¦ â”† 1         â”† 04        â”† NN        â”† N        â”‚\n",
      "â”‚           â”† 1         â”†           â”†           â”†   â”†           â”†           â”†           â”†          â”‚\n",
      "â”‚ 005541552 â”† 1974-01-0 â”† null      â”† 0         â”† â€¦ â”† 1         â”† 04        â”† 01        â”† O        â”‚\n",
      "â”‚           â”† 1         â”†           â”†           â”†   â”†           â”†           â”†           â”†          â”‚\n",
      "â”‚ 005641154 â”† 1981-02-0 â”† null      â”† 0         â”† â€¦ â”† 2         â”† 04        â”† NN        â”† N        â”‚\n",
      "â”‚           â”† 1         â”†           â”†           â”†   â”†           â”†           â”†           â”†          â”‚\n",
      "â”‚ 005742580 â”† 1993-03-0 â”† null      â”† 0         â”† â€¦ â”† 3         â”† 04        â”† NN        â”† N        â”‚\n",
      "â”‚           â”† 1         â”†           â”†           â”†   â”†           â”†           â”†           â”†          â”‚\n",
      "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "import pyarrow.parquet as pq\n",
    "import sys\n",
    "\n",
    "filepath = \"../Data/processed/sirene_infos.parquet\" \n",
    "\n",
    "print(\"--- DÃ©but de la lecture 'bypass' ---\")\n",
    "\n",
    "try:\n",
    "    print(f\"Lecture du fichier via PyArrow : {filepath}\")\n",
    "    table_arrow = pq.read_table(\n",
    "        filepath,\n",
    "    )\n",
    "    \n",
    "    print(\"Conversion de la table PyArrow en DataFrame Polars...\")\n",
    "    df_demo = pl.from_arrow(table_arrow)\n",
    "    \n",
    "    print(\"--- SUCCÃˆS ! ---\\n\")\n",
    "    print(\"Le DataFrame est maintenant dans Polars, prÃªt pour la transformation.\")\n",
    "    print(df_demo.head())\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\n--- ERREUR ---\", file=sys.stderr)\n",
    "    print(f\"Impossible de lire le fichier, mÃªme avec PyArrow : {e}\", file=sys.stderr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# EDA Bilan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- DÃ©but de la lecture 'bypass' ---\n",
      "Lecture du fichier via PyArrow : ../Data/processed/sirene_bilan.parquet\n",
      "Conversion de la table PyArrow en DataFrame Polars...\n",
      "--- SUCCÃˆS ! ---\n",
      "\n",
      "Le DataFrame est maintenant dans Polars, prÃªt pour la transformation.\n",
      "shape: (5, 21)\n",
      "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
      "â”‚ siren     â”† date_clot â”† CJCK_Tota â”† EG_Impots â”† â€¦ â”† ratio_cap â”† ratio_tre â”† ratio_res â”† ratio_re â”‚\n",
      "â”‚ ---       â”† ure_exerc â”† lActifBru â”† Taxes     â”†   â”† itaux_pro â”† sorerie   â”† ultat_fin â”† sultat_e â”‚\n",
      "â”‚ str       â”† ice       â”† t         â”† ---       â”†   â”† pres      â”† ---       â”† ancier    â”† xception â”‚\n",
      "â”‚           â”† ---       â”† ---       â”† i32       â”†   â”† ---       â”† f64       â”† ---       â”† nel      â”‚\n",
      "â”‚           â”† date      â”† i32       â”†           â”†   â”† f64       â”†           â”† f64       â”† ---      â”‚\n",
      "â”‚           â”†           â”†           â”†           â”†   â”†           â”†           â”†           â”† f64      â”‚\n",
      "â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•¡\n",
      "â”‚ 005420120 â”† 2018-12-3 â”† 15117606  â”† 841098    â”† â€¦ â”† 0.0       â”† 0.047087  â”† 29.374216 â”† 101.8593 â”‚\n",
      "â”‚           â”† 1         â”†           â”†           â”†   â”†           â”†           â”†           â”† 99       â”‚\n",
      "â”‚ 005420120 â”† 2021-12-3 â”† 10813111  â”† 2500000   â”† â€¦ â”† 0.0       â”† 0.065831  â”† 6.162617  â”† 14.06566 â”‚\n",
      "â”‚           â”† 1         â”†           â”†           â”†   â”†           â”†           â”†           â”† 4        â”‚\n",
      "â”‚ 005420120 â”† 2017-12-3 â”† 22684824  â”† 441247    â”† â€¦ â”† 0.0       â”† 0.03138   â”† 3.745877  â”† 17.20460 â”‚\n",
      "â”‚           â”† 1         â”†           â”†           â”†   â”†           â”†           â”†           â”† 4        â”‚\n",
      "â”‚ 005420120 â”† 2016-12-3 â”† 31933093  â”† 586967    â”† â€¦ â”† 0.0       â”† 0.022292  â”† 8.805762  â”† 66.05635 â”‚\n",
      "â”‚           â”† 1         â”†           â”†           â”†   â”†           â”†           â”†           â”† 3        â”‚\n",
      "â”‚ 005420120 â”† 2019-12-3 â”† 12736527  â”† 0         â”† â€¦ â”† 0.0       â”† 0.05589   â”† 4.502626  â”† 10.75797 â”‚\n",
      "â”‚           â”† 1         â”†           â”†           â”†   â”†           â”†           â”†           â”†          â”‚\n",
      "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "import pyarrow.parquet as pq\n",
    "import sys\n",
    "\n",
    "filepath = \"../Data/processed/sirene_bilan.parquet\" \n",
    "\n",
    "print(\"--- DÃ©but de la lecture 'bypass' ---\")\n",
    "\n",
    "try:\n",
    "    print(f\"Lecture du fichier via PyArrow : {filepath}\")\n",
    "    table_arrow = pq.read_table(\n",
    "        filepath,\n",
    "    )\n",
    "    \n",
    "    print(\"Conversion de la table PyArrow en DataFrame Polars...\")\n",
    "    df_bilan = pl.from_arrow(table_arrow)\n",
    "    \n",
    "    print(\"--- SUCCÃˆS ! ---\\n\")\n",
    "    print(\"Le DataFrame est maintenant dans Polars, prÃªt pour la transformation.\")\n",
    "    print(df_bilan.head())\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\n--- ERREUR ---\", file=sys.stderr)\n",
    "    print(f\"Impossible de lire le fichier, mÃªme avec PyArrow : {e}\", file=sys.stderr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ğŸš€ Plan DÃ©taillÃ© de l'Exploratory Data Analysis (EDA) : eda.ipynb\n",
    "\n",
    "Ce plan d'EDA a pour objectif de justifier les choix de features et de modÃ©lisation pour la prÃ©diction du RÃ©sultat Net Ã  un an, en se basant sur l'ensemble d'entraÃ®nement ($T=2018$ pour prÃ©dire $Y=2019$)\n",
    "\n",
    "## 1. ğŸ“ Introduction et Structuration de l'AnalyseCette section assure la conformitÃ© du projet en termes de contexte business et de qualitÃ© du jeu de donnÃ©es\n",
    "\n",
    "Section Objectif / (Exigence du Projet) / Livrable\n",
    "\n",
    "1.1 Contexte & BUCDÃ©finir clairement le dÃ©fi commercial : PrÃ©diction du RÃ©sultat Net Ã  $T+1$2.Texte.\n",
    "\n",
    "1.2 Description du DatasetConfirmer l'utilisation d'un jeu de donnÃ©es issu d'un scÃ©nario rÃ©el 3 et sa structure aprÃ¨s nettoyage (SIRENs complets 2017-2020).Affichage de df_filtre.shape et df_filtre.dtypes.\n",
    "\n",
    "1.3 DÃ©finition de l'Ã‰chantillonIsoler l'ensemble d'entraÃ®nement pour l'EDA : Features 2018 ($T$) & Cible 2019 ($Y_{T+1}$).Affichage de X_train.shape et y_train.shape.\n",
    "\n",
    "## 2. ğŸ¯ Analyse UnivariÃ©e de la Cible ($Y$) : La PrÃ©dictionL'analyse de la cible est prioritaire pour choisir la bonne technique de modÃ©lisation (rÃ©gression)\n",
    "\n",
    "Section / Analyse Visualisation & Justification\n",
    "\n",
    "2.1 Statistiques DescriptivesCaractÃ©riser la distribution de la cible (cible_ResultatNet_T_plus_1) : Moyenne, MÃ©diane, Min, Max.Tableau de statistiques descriptives.\n",
    "\n",
    "2.2 Distribution et OutliersÃ‰valuer l'asymÃ©trie de la cible. Les donnÃ©es financiÃ¨res sont typiquement trÃ¨s asymÃ©triques.Histogramme (avec Ã©chelle log sur Y pour gÃ©rer la forte asymÃ©trie).\n",
    "\n",
    "2.3 TransformationProposer le traitement des outliers et justifier l'utilisation potentielle d'une transformation (ex: $\\ln(1+Y)$) pour normaliser la cible et amÃ©liorer les performances du modÃ¨le de rÃ©gression.Box Plot (pour visualiser les valeurs extrÃªmes).\n",
    "\n",
    "## 3. ğŸ“‰ Analyse BivariÃ©e : SÃ©lection des Features (Rigueur Data Science)\n",
    "\n",
    "Le but est de dÃ©terminer quelles features (valeurs $T$, ratios $T$, ou deltas $T$ vs $T-1$) sont les plus prÃ©dictives5.SectionAnalyseVisualisation & Justification\n",
    "\n",
    "3.1 Matrice de CorrÃ©lationCalculer la corrÃ©lation de Pearson entre la cible $Y_{2019}$ et toutes les features candidates.Heatmap de la matrice de corrÃ©lation.\n",
    "\n",
    "3.2 Validation du Feature EngineeringComparer la corrÃ©lation des Deltas (delta_CA, delta_ResultatNet) avec la corrÃ©lation des valeurs absolues ($T$). Justifier le choix des deltas.Affichage des coefficients de corrÃ©lation les plus Ã©levÃ©s (Top 5).\n",
    "\n",
    "3.3 CorrÃ©lation ClÃ© (CA)Illustrer la relation la plus forte (ex: delta_CA vs $Y_{T+1}$) pour montrer la tendance.Scatter Plot (Diagramme de dispersion).\n",
    "\n",
    "## 4. ğŸ§¹ QualitÃ© des DonnÃ©es et Pre-Processing (Meilleures Pratiques)\n",
    "Cette section garantit la qualitÃ© des artefacts de ML666.SectionAnalyseImplication pour le ML\n",
    "\n",
    "4.1 Valeurs ExtrÃªmes des FeaturesDÃ©tecter les entreprises avec des actifs/CA aberrants (FA_ChiffreAffairesVentes, CJCK_TotalActifBrut).DÃ©cision d'appliquer une Standardisation/Normalisation pour les modÃ¨les sensibles aux Ã©chelles.\n",
    "\n",
    "4.2 Gestion des ZÃ©ros/InfIdentifier les cas oÃ¹ les ratios deviennent $\\pm \\infty$ ou NaN (ex: division par 0 du CA).Justification d'une imputation ou de l'exclusion des ratios problÃ©matiques dans le Pre-Processing.5. ğŸ“ Conclusion et Plan d'ExpÃ©rimentationCette section sert de pont vers l'implÃ©mentation dans main.py et dÃ©finit la stratÃ©gie d'itÃ©ration et de suivi.SectionSynthÃ¨se et Plan d'ActionExigence du Projet\n",
    "\n",
    "## 5. SynthÃ¨se de la PrÃ©dictionRÃ©sumer les features sÃ©lectionnÃ©es (basÃ©es sur les corrÃ©lations).\n",
    "\n",
    "Justification Data Science.\n",
    "\n",
    "5.1 SynthÃ¨se de la PrÃ©diction\tRÃ©sumer les features sÃ©lectionnÃ©es (basÃ©es sur les corrÃ©lations).\tJustification Data Science.\n",
    "\n",
    "5.2 Proposition de BaselineDÃ©finir le modÃ¨le simple initial (ex: RÃ©gression LinÃ©aire) et les features minimales Ã  utiliser7.Baseline Obligatoire8.\n",
    "\n",
    "5.3 Plan d'ExpÃ©rimentationDÃ©finir les premiÃ¨res Ã©tapes d'itÃ©ration (ajout des Deltas, changement de modÃ¨le non-linÃ©aire) et l'importance du suivi des mÃ©triques.Experimentation Tracking999999999."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… DataFrame de Training (T=2018, Cible Y=2019) chargÃ© en Pandas.\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# Configuration visuelle\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "# --- DÃ©finition des colonnes ---\n",
    "cible_col = \"cible_ResultatNet_T_plus_1\"\n",
    "\n",
    "# --- Remplacement des placeholders pour la dÃ©monstration (Ã€ adapter) ---\n",
    "# Assurez-vous que df_features est dÃ©fini et contient les donnÃ©es enrichies T=2017 Ã  T=2020.\n",
    "try:\n",
    "    df_features\n",
    "except NameError:\n",
    "    print(\"ATTENTION : df_features non trouvÃ©. Veuillez exÃ©cuter les Ã©tapes de prÃ©paration des donnÃ©es pour le Feature Engineering.\")\n",
    "    # Simuler df_features pour les stats si le bloc prÃ©cÃ©dent n'a pas Ã©tÃ© exÃ©cutÃ©\n",
    "    N = 286323 # Taille simulÃ©e d'aprÃ¨s votre image prÃ©cÃ©dente\n",
    "    df_features = pl.DataFrame({\n",
    "        \"AnneeClotureExercice\": np.repeat([2017, 2018, 2019, 2020], N//4),\n",
    "        cible_col: np.concatenate([np.random.rand(N//4)*1e3 - 500, np.random.rand(N - N//4)*1e5]), # AsymÃ©trie simulÃ©e\n",
    "        \"FA_ChiffreAffairesVentes\": np.random.randint(100, 100000, N),\n",
    "        \"delta_CA\": np.random.randint(-50000, 50000, N),\n",
    "        \"delta_ResultatNet\": np.concatenate([np.random.rand(N)*1e3 - 500, np.random.rand(N - N//4)*1e5]),\n",
    "        \"ratio_rentabilite_nette\": np.random.rand(N) * 0.5 - 0.2\n",
    "    }).filter(pl.col(\"AnneeClotureExercice\") == 2018) # Filtrer pour T=2018\n",
    "\n",
    "# --- CrÃ©ation du DataFrame d'entraÃ®nement pour l'EDA (T=2018, Cible Y=2019) ---\n",
    "df_train_pl = df_features.filter(pl.col(\"AnneeClotureExercice\") == 2018)\n",
    "df_train_pd = df_train_pl.to_pandas()\n",
    "\n",
    "# Calcul des statistiques et dimensions pour les tableaux Markdown\n",
    "stats_cible = df_train_pd[cible_col].describe()\n",
    "nombre_lignes = df_train_pd.shape[0]\n",
    "nombre_colonnes = df_train_pd.shape[1]\n",
    "\n",
    "print(f\"âœ… DataFrame de Training (T=2018, Cible Y=2019) chargÃ© en Pandas.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
