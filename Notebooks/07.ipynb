{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ugo/Documents/Cours/Master/Cours/M1/Supervised Learning/Final Project/.venv/lib/python3.13/site-packages/mlflow/tracking/_tracking_service/utils.py:140: FutureWarning: Filesystem tracking backend (e.g., './mlruns') is deprecated. Please switch to a database backend (e.g., 'sqlite:///mlflow.db'). For feedback, see: https://github.com/mlflow/mlflow/issues/18534\n",
      "  return FileStore(store_uri, store_uri)\n",
      "2025/11/16 17:48:22 INFO mlflow.tracking.fluent: Experiment with name 'Projet_SIRENE_Regression_Monstre' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLflow configuré pour le 'Run Monstrueux'.\n",
      "Chargement des 'Master files'...\n",
      "Fichiers 'infos' et 'bilan' chargés.\n",
      "Création du dataset temporel (N, N-1, N-2)...\n",
      "Création des features de 'Vélocité' et 'Accélération'...\n",
      "Dataset de Régression 'Monstre' créé. Shape: (415027, 58)\n",
      "Total features: 2 cat + 54 num.\n",
      "Clipping des outliers...\n",
      "Preprocessing avec RobustScaler (Num) + OHE (Cat)...\n",
      "Création de la pipeline (Preprocessor + XGB Regressor)...\n",
      "Preprocessing terminé. Lancement du tuning (peut prendre 10-20 minutes)...\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "[CV] END learning_rate=0.05, max_depth=5, n_estimators=100, subsample=1.0; total time=  20.2s\n",
      "[CV] END learning_rate=0.05, max_depth=5, n_estimators=100, subsample=1.0; total time=  20.5s\n",
      "[CV] END learning_rate=0.05, max_depth=5, n_estimators=100, subsample=1.0; total time=  20.7s\n",
      "[CV] END learning_rate=0.05, max_depth=5, n_estimators=100, subsample=1.0; total time=  21.0s\n",
      "[CV] END learning_rate=0.05, max_depth=5, n_estimators=100, subsample=1.0; total time=  21.0s\n",
      "[CV] END learning_rate=0.01, max_depth=10, n_estimators=100, subsample=0.7; total time=  30.8s\n",
      "[CV] END learning_rate=0.01, max_depth=10, n_estimators=100, subsample=0.7; total time=  31.1s\n",
      "[CV] END learning_rate=0.01, max_depth=10, n_estimators=100, subsample=1.0; total time=  31.3s\n",
      "[CV] END learning_rate=0.01, max_depth=10, n_estimators=100, subsample=1.0; total time=  31.4s\n",
      "[CV] END learning_rate=0.01, max_depth=10, n_estimators=100, subsample=1.0; total time=  31.4s\n",
      "[CV] END learning_rate=0.01, max_depth=10, n_estimators=100, subsample=1.0; total time=  31.7s\n",
      "[CV] END learning_rate=0.01, max_depth=10, n_estimators=100, subsample=1.0; total time=  31.7s\n",
      "[CV] END learning_rate=0.1, max_depth=10, n_estimators=100, subsample=0.7; total time=  19.2s\n",
      "[CV] END learning_rate=0.1, max_depth=10, n_estimators=100, subsample=0.7; total time=  19.5s\n",
      "[CV] END learning_rate=0.01, max_depth=10, n_estimators=100, subsample=0.7; total time=  25.2s\n",
      "[CV] END learning_rate=0.01, max_depth=10, n_estimators=100, subsample=0.7; total time=  25.1s\n",
      "[CV] END learning_rate=0.01, max_depth=10, n_estimators=100, subsample=0.7; total time=  25.5s\n",
      "[CV] END learning_rate=0.1, max_depth=10, n_estimators=100, subsample=0.7; total time=  21.8s\n",
      "[CV] END learning_rate=0.1, max_depth=10, n_estimators=100, subsample=0.7; total time=  21.8s\n",
      "[CV] END learning_rate=0.1, max_depth=10, n_estimators=100, subsample=0.7; total time=  22.3s\n",
      "[CV] END learning_rate=0.01, max_depth=7, n_estimators=250, subsample=0.7; total time=  41.3s\n",
      "[CV] END learning_rate=0.01, max_depth=7, n_estimators=250, subsample=0.7; total time=  41.1s\n",
      "[CV] END learning_rate=0.01, max_depth=7, n_estimators=250, subsample=0.7; total time=  41.8s\n",
      "[CV] END learning_rate=0.01, max_depth=7, n_estimators=250, subsample=0.7; total time=  41.7s\n",
      "[CV] END learning_rate=0.1, max_depth=5, n_estimators=400, subsample=1.0; total time=  33.6s\n",
      "[CV] END learning_rate=0.01, max_depth=7, n_estimators=250, subsample=0.7; total time=  37.8s\n",
      "[CV] END learning_rate=0.1, max_depth=5, n_estimators=400, subsample=1.0; total time=  33.8s\n",
      "[CV] END learning_rate=0.1, max_depth=5, n_estimators=400, subsample=1.0; total time=  33.6s\n",
      "[CV] END learning_rate=0.1, max_depth=5, n_estimators=400, subsample=1.0; total time=  33.9s\n",
      "[CV] END learning_rate=0.1, max_depth=5, n_estimators=400, subsample=1.0; total time=  33.3s\n",
      "[CV] END learning_rate=0.1, max_depth=5, n_estimators=250, subsample=1.0; total time=  23.1s\n",
      "[CV] END learning_rate=0.1, max_depth=10, n_estimators=400, subsample=1.0; total time=  51.9s\n",
      "[CV] END learning_rate=0.1, max_depth=10, n_estimators=400, subsample=1.0; total time=  52.0s\n",
      "[CV] END learning_rate=0.1, max_depth=5, n_estimators=250, subsample=1.0; total time=  22.8s\n",
      "[CV] END learning_rate=0.1, max_depth=10, n_estimators=400, subsample=1.0; total time=  52.3s\n",
      "[CV] END learning_rate=0.1, max_depth=10, n_estimators=400, subsample=1.0; total time=  52.6s\n",
      "[CV] END learning_rate=0.1, max_depth=10, n_estimators=400, subsample=1.0; total time=  52.2s\n",
      "[CV] END learning_rate=0.1, max_depth=5, n_estimators=250, subsample=1.0; total time=  22.7s\n",
      "[CV] END learning_rate=0.1, max_depth=5, n_estimators=250, subsample=1.0; total time=  22.9s\n",
      "[CV] END learning_rate=0.1, max_depth=5, n_estimators=250, subsample=1.0; total time=  22.7s\n",
      "[CV] END learning_rate=0.1, max_depth=10, n_estimators=100, subsample=1.0; total time=  18.8s\n",
      "[CV] END learning_rate=0.1, max_depth=10, n_estimators=100, subsample=1.0; total time=  18.4s\n",
      "[CV] END learning_rate=0.05, max_depth=10, n_estimators=250, subsample=0.7; total time=  41.4s\n",
      "[CV] END learning_rate=0.01, max_depth=10, n_estimators=400, subsample=0.7; total time= 1.3min\n",
      "[CV] END learning_rate=0.01, max_depth=10, n_estimators=400, subsample=0.7; total time= 1.3min\n",
      "[CV] END learning_rate=0.01, max_depth=10, n_estimators=400, subsample=0.7; total time= 1.3min\n",
      "[CV] END learning_rate=0.01, max_depth=10, n_estimators=400, subsample=0.7; total time= 1.4min\n",
      "[CV] END learning_rate=0.01, max_depth=10, n_estimators=400, subsample=0.7; total time= 1.4min\n",
      "[CV] END learning_rate=0.05, max_depth=10, n_estimators=250, subsample=0.7; total time=  41.9s\n",
      "[CV] END learning_rate=0.1, max_depth=10, n_estimators=100, subsample=1.0; total time=  18.4s\n",
      "[CV] END learning_rate=0.1, max_depth=10, n_estimators=100, subsample=1.0; total time=  18.6s\n",
      "[CV] END learning_rate=0.05, max_depth=10, n_estimators=250, subsample=0.7; total time=  41.9s\n",
      "[CV] END learning_rate=0.05, max_depth=10, n_estimators=250, subsample=0.7; total time=  42.5s\n",
      "[CV] END learning_rate=0.05, max_depth=10, n_estimators=250, subsample=0.7; total time=  43.0s\n",
      "[CV] END learning_rate=0.1, max_depth=10, n_estimators=100, subsample=1.0; total time=  18.4s\n",
      "[CV] END learning_rate=0.1, max_depth=7, n_estimators=250, subsample=0.7; total time=  28.7s\n",
      "[CV] END learning_rate=0.1, max_depth=7, n_estimators=250, subsample=0.7; total time=  28.1s\n",
      "[CV] END learning_rate=0.1, max_depth=7, n_estimators=100, subsample=0.7; total time=  15.1s\n",
      "[CV] END learning_rate=0.1, max_depth=7, n_estimators=100, subsample=0.7; total time=  15.1s\n",
      "[CV] END learning_rate=0.1, max_depth=7, n_estimators=250, subsample=0.7; total time=  28.6s\n",
      "[CV] END learning_rate=0.1, max_depth=7, n_estimators=250, subsample=0.7; total time=  27.4s\n",
      "[CV] END learning_rate=0.1, max_depth=7, n_estimators=250, subsample=0.7; total time=  28.0s\n",
      "[CV] END learning_rate=0.1, max_depth=7, n_estimators=100, subsample=0.7; total time=  14.5s\n",
      "[CV] END learning_rate=0.05, max_depth=7, n_estimators=250, subsample=0.7; total time=  30.6s\n",
      "[CV] END learning_rate=0.1, max_depth=7, n_estimators=100, subsample=0.7; total time=  14.7s\n",
      "[CV] END learning_rate=0.05, max_depth=7, n_estimators=250, subsample=0.7; total time=  30.8s\n",
      "[CV] END learning_rate=0.1, max_depth=7, n_estimators=100, subsample=0.7; total time=  14.8s\n",
      "[CV] END learning_rate=0.05, max_depth=7, n_estimators=250, subsample=0.7; total time=  30.9s\n",
      "[CV] END learning_rate=0.05, max_depth=7, n_estimators=250, subsample=0.7; total time=  31.2s\n",
      "[CV] END learning_rate=0.05, max_depth=7, n_estimators=250, subsample=0.7; total time=  30.8s\n",
      "[CV] END learning_rate=0.01, max_depth=5, n_estimators=100, subsample=1.0; total time=  15.6s\n",
      "[CV] END learning_rate=0.01, max_depth=5, n_estimators=100, subsample=1.0; total time=  16.0s\n",
      "[CV] END learning_rate=0.01, max_depth=5, n_estimators=100, subsample=1.0; total time=  14.8s\n",
      "[CV] END learning_rate=0.01, max_depth=5, n_estimators=100, subsample=1.0; total time=  15.0s\n",
      "[CV] END learning_rate=0.1, max_depth=5, n_estimators=400, subsample=0.7; total time=  37.2s\n",
      "[CV] END learning_rate=0.1, max_depth=5, n_estimators=400, subsample=0.7; total time=  37.3s\n",
      "[CV] END learning_rate=0.1, max_depth=5, n_estimators=400, subsample=0.7; total time=  37.2s\n",
      "[CV] END learning_rate=0.1, max_depth=5, n_estimators=400, subsample=0.7; total time=  37.5s\n",
      "[CV] END learning_rate=0.1, max_depth=5, n_estimators=400, subsample=0.7; total time=  37.7s\n",
      "[CV] END learning_rate=0.01, max_depth=5, n_estimators=100, subsample=1.0; total time=  14.3s\n",
      "[CV] END learning_rate=0.05, max_depth=10, n_estimators=400, subsample=0.7; total time= 1.0min\n",
      "[CV] END learning_rate=0.05, max_depth=7, n_estimators=100, subsample=0.7; total time=  16.6s\n",
      "[CV] END learning_rate=0.05, max_depth=10, n_estimators=400, subsample=0.7; total time= 1.1min\n",
      "[CV] END learning_rate=0.05, max_depth=10, n_estimators=400, subsample=0.7; total time= 1.1min\n",
      "[CV] END learning_rate=0.05, max_depth=7, n_estimators=100, subsample=0.7; total time=  16.7s\n",
      "[CV] END learning_rate=0.05, max_depth=10, n_estimators=400, subsample=0.7; total time= 1.0min\n",
      "[CV] END learning_rate=0.05, max_depth=7, n_estimators=100, subsample=0.7; total time=  17.0s\n",
      "[CV] END learning_rate=0.05, max_depth=7, n_estimators=100, subsample=0.7; total time=  17.0s\n",
      "[CV] END learning_rate=0.05, max_depth=7, n_estimators=100, subsample=0.7; total time=  16.7s\n",
      "[CV] END learning_rate=0.05, max_depth=10, n_estimators=400, subsample=0.7; total time= 1.0min\n",
      "[CV] END learning_rate=0.01, max_depth=7, n_estimators=250, subsample=1.0; total time=  36.4s\n",
      "[CV] END learning_rate=0.01, max_depth=7, n_estimators=250, subsample=1.0; total time=  34.7s\n",
      "[CV] END learning_rate=0.01, max_depth=7, n_estimators=250, subsample=1.0; total time=  34.9s\n",
      "[CV] END learning_rate=0.01, max_depth=7, n_estimators=250, subsample=1.0; total time=  34.1s\n",
      "[CV] END learning_rate=0.05, max_depth=10, n_estimators=250, subsample=1.0; total time=  32.5s\n",
      "[CV] END learning_rate=0.01, max_depth=7, n_estimators=250, subsample=1.0; total time=  33.4s\n",
      "[CV] END learning_rate=0.05, max_depth=10, n_estimators=250, subsample=1.0; total time=  33.4s\n",
      "[CV] END learning_rate=0.05, max_depth=10, n_estimators=250, subsample=1.0; total time=  32.9s\n",
      "[CV] END learning_rate=0.05, max_depth=10, n_estimators=250, subsample=1.0; total time=  32.3s\n",
      "[CV] END learning_rate=0.05, max_depth=10, n_estimators=250, subsample=1.0; total time=  32.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/16 17:53:23 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "--- RÉSULTATS DU TUNING 'MONSTRUEUX' (RANDOMIZEDSEARCHCV) ---\n",
      "Meilleur Score R² trouvé : 0.3294\n",
      "Meilleurs Hyperparamètres :\n",
      "{'subsample': 0.7, 'n_estimators': 400, 'max_depth': 10, 'learning_rate': 0.01}\n",
      "---\n",
      "Score précédent (Modèle F, non-tuné): 0.3091\n",
      "Score actuel (Modèle H, tuné): 0.3294\n",
      "---\n",
      "Toutes les expériences sont loggées dans 'mlruns'.\n",
      "Lance 'mlflow ui' dans ton terminal pour voir le dashboard.\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold, GridSearchCV\n",
    "from sklearn.preprocessing import RobustScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import make_scorer, r2_score\n",
    "from xgboost import XGBRegressor\n",
    "import mlflow\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "\n",
    "# --- 1. CONFIGURER MLFLOW ---\n",
    "mlflow.set_experiment(\"Projet_SIRENE_Regression_Monstre\")\n",
    "mlflow.xgboost.autolog()\n",
    "print(\"MLflow configuré pour le 'Run Monstrueux'.\")\n",
    "\n",
    "# --- 2. CHARGER LES BONS \"MASTER FILES\" ---\n",
    "print(\"Chargement des 'Master files'...\")\n",
    "df_sirene = pl.read_parquet(\"../Data/processed/sirene_infos.parquet\")\n",
    "df_bilan = pl.read_parquet(\"../Data/processed/sirene_bilan.parquet\")\n",
    "print(\"Fichiers 'infos' et 'bilan' chargés.\")\n",
    "\n",
    "# --- 3. DÉFINIR LES CODES \"DIAMANT\" ---\n",
    "RAW_CODES = [\n",
    "    'HN_RésultatNet', 'FA_ChiffreAffairesVentes', 'FB_AchatsMarchandises',\n",
    "    'CJCK_TotalActifBrut', 'DL_DettesCourtTerme', 'DM_DettesLongTerme',\n",
    "    'DA_TresorerieActive', 'FJ_ResultatFinancier', 'FR_ResultatExceptionnel',\n",
    "    'DF_CapitauxPropres', 'EG_ImpotsTaxes'\n",
    "]\n",
    "RATIO_CODES = [\n",
    "    \"ratio_rentabilite_nette\", \"ratio_endettement\", \"ratio_marge_brute\", \n",
    "    \"ratio_capitaux_propres\", \"ratio_tresorerie\",\n",
    "    \"ratio_resultat_financier\", \"ratio_resultat_exceptionnel\"\n",
    "]\n",
    "FINANCIAL_FEATURES = RAW_CODES + RATIO_CODES\n",
    "CATEGORICAL_FEATURES = [\"categorieJuridiqueUniteLegale\", \"departement\"]\n",
    "TARGET = \"TARGET_rentabilite_N\"\n",
    "\n",
    "# --- 4. CRÉATION DU DATASET (LE \"SELF-JOIN\" TEMPOREL) ---\n",
    "print(\"Création du dataset temporel (N, N-1, N-2)...\")\n",
    "\n",
    "# A. Données N (2019) - LA TARGET\n",
    "df_N = df_bilan.filter(pl.col(\"AnneeClotureExercice\") == 2019).select(\n",
    "    \"siren\", pl.col(\"ratio_rentabilite_nette\").alias(TARGET)\n",
    ")\n",
    "\n",
    "# B. Données N-1 (2018) - Features \"État\"\n",
    "df_N_moins_1 = df_bilan.filter(pl.col(\"AnneeClotureExercice\") == 2018).select(\n",
    "    \"siren\", *[pl.col(c).alias(f\"{c}_N1\") for c in FINANCIAL_FEATURES]\n",
    ")\n",
    "\n",
    "# C. Données N-2 (2017) - Features \"Historique\"\n",
    "df_N_moins_2 = df_bilan.filter(pl.col(\"AnneeClotureExercice\") == 2017).select(\n",
    "    \"siren\", *[pl.col(c).alias(f\"{c}_N2\") for c in FINANCIAL_FEATURES]\n",
    ")\n",
    "\n",
    "# --- 5. LE FEATURE ENGINEERING \"MONSTRUEUX\" ---\n",
    "print(\"Création des features de 'Vélocité' et 'Accélération'...\")\n",
    "# On joint N-1 et N-2\n",
    "df_features = df_N_moins_1.join(df_N_moins_2, on=\"siren\", how=\"left\").fill_null(0)\n",
    "\n",
    "# On crée les features de \"Vélocité\" (Variation N-1 vs N-2)\n",
    "for c in FINANCIAL_FEATURES:\n",
    "    df_features = df_features.with_columns(\n",
    "        (pl.col(f\"{c}_N1\") - pl.col(f\"{c}_N2\")).alias(f\"var_{c}_N1_N2\")\n",
    "    )\n",
    "\n",
    "# On joint avec les features \"Démo\" (le châssis !)\n",
    "df_features = df_features.join(\n",
    "    df_sirene.select(\"siren\", *CATEGORICAL_FEATURES),\n",
    "    on=\"siren\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# --- 6. JOINTURE FINALE (Features + Target) ---\n",
    "df_ml = df_features.join(df_N, on=\"siren\", how=\"inner\")\n",
    "print(f\"Dataset de Régression 'Monstre' créé. Shape: {df_ml.shape}\")\n",
    "\n",
    "# --- 7. DÉFINITION FINALE DES FEATURES (X) ET TARGET (Y) ---\n",
    "# On prend TOUT : État N-1, État N-2, Variations, et Démo\n",
    "NUMERIC_FEATURES_FINAL = [c for c in df_ml.columns if c not in [\"siren\", TARGET] + CATEGORICAL_FEATURES]\n",
    "print(f\"Total features: {len(CATEGORICAL_FEATURES)} cat + {len(NUMERIC_FEATURES_FINAL)} num.\")\n",
    "\n",
    "# --- 8. NETTOYAGE DES OUTLIERS (Clipping) ---\n",
    "print(\"Clipping des outliers...\")\n",
    "LOWER_BOUND, UPPER_BOUND = -5.0, 5.0\n",
    "clip_cols = [c for c in NUMERIC_FEATURES_FINAL if \"ratio\" in c or \"variation\" in c]\n",
    "df_ml = df_ml.with_columns(\n",
    "    pl.col(clip_cols).clip(lower_bound=LOWER_BOUND, upper_bound=UPPER_BOUND),\n",
    "    pl.col(TARGET).clip(lower_bound=LOWER_BOUND, upper_bound=UPPER_BOUND)\n",
    ").fill_null(0)\n",
    "\n",
    "# Conversion en Pandas\n",
    "X = df_ml.select(NUMERIC_FEATURES_FINAL + CATEGORICAL_FEATURES).to_pandas()\n",
    "y = df_ml.select(TARGET).to_pandas().squeeze()\n",
    "\n",
    "# --- 9. PRÉPARATION (Le Preprocessor \"Monstre\") ---\n",
    "print(\"Preprocessing avec RobustScaler (Num) + OHE (Cat)...\")\n",
    "numerical_transformer = RobustScaler()\n",
    "categorical_transformer = OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numerical_transformer, NUMERIC_FEATURES_FINAL),\n",
    "        (\"cat\", categorical_transformer, CATEGORICAL_FEATURES)\n",
    "    ],\n",
    "    remainder=\"passthrough\"\n",
    ")\n",
    "\n",
    "# --- 10. CRÉATION DE LA PIPELINE ET TUNING ---\n",
    "print(\"Création de la pipeline (Preprocessor + XGB Regressor)...\")\n",
    "pipeline_preprocessor = Pipeline(steps=[('preprocessor', preprocessor)])\n",
    "print(\"Preprocessing terminé. Lancement du tuning (peut prendre 10-20 minutes)...\")\n",
    "\n",
    "# Grille de tuning plus large\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 250, 400],\n",
    "    'max_depth': [5, 7, 10],\n",
    "    'learning_rate': [0.1, 0.05, 0.01],\n",
    "    'subsample': [0.7, 1.0] # Ajout de subsample pour la robustesse\n",
    "}\n",
    "# Total d'expériences : 3 * 3 * 3 * 2 = 54 (x 5 folds = 270 entraînements)\n",
    "# C'EST LENT. On va utiliser RandomizedSearchCV pour en tester 20.\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "xgb_reg = XGBRegressor(objective='reg:squarederror', eval_metric='rmse', random_state=42)\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# On utilise RandomizedSearchCV pour aller plus vite\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=xgb_reg,\n",
    "    param_distributions=param_grid,\n",
    "    n_iter=20, # On ne teste que 20 combinaisons au hasard\n",
    "    cv=kfold,\n",
    "    scoring='r2',\n",
    "    verbose=2,\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "X_processed = pipeline_preprocessor.fit_transform(X)\n",
    "\n",
    "with mlflow.start_run() as run:\n",
    "    random_search.fit(X_processed, y)\n",
    "    mlflow.log_param(\"model_type\", \"Model_H_Full_Velocity_Tuned\")\n",
    "    mlflow.log_metric(\"best_r2_score\", random_search.best_score_)\n",
    "\n",
    "# --- 11. RÉSULTATS DU TUNING \"MONSTRUEUX\" ---\n",
    "print(\"---\")\n",
    "print(\"--- RÉSULTATS DU TUNING 'MONSTRUEUX' (RANDOMIZEDSEARCHCV) ---\")\n",
    "print(f\"Meilleur Score R² trouvé : {random_search.best_score_:.4f}\")\n",
    "print(\"Meilleurs Hyperparamètres :\")\n",
    "print(random_search.best_params_)\n",
    "print(\"---\")\n",
    "print(f\"Score précédent (Modèle F, non-tuné): 0.3091\")\n",
    "print(f\"Score actuel (Modèle H, tuné): {random_search.best_score_:.4f}\")\n",
    "print(\"---\")\n",
    "print(\"Toutes les expériences sont loggées dans 'mlruns'.\")\n",
    "print(\"Lance 'mlflow ui' dans ton terminal pour voir le dashboard.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
