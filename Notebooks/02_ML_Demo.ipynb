{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jeu de données complet (T=2017 -> Y=2018) chargé. Taille: 29960 observations.\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, make_scorer\n",
    "import numpy as np\n",
    "import warnings\n",
    "from typing import Dict, Any\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# --- 0. Chargement et Préparation ---\n",
    "FILE_PATH_ML = \"../Data/processed/sirene_bilan_ML_prets.parquet\" \n",
    "cible_col = \"cible_HN_RésultatNet_T_plus_1\"\n",
    "\n",
    "try:\n",
    "    df_ml = pl.read_parquet(FILE_PATH_ML)\n",
    "except Exception as e:\n",
    "    print(f\"ERREUR : Impossible de charger le fichier ML. Vérifiez le chemin : {FILE_PATH_ML}\")\n",
    "    raise\n",
    "\n",
    "df_ml_pd = df_ml.to_pandas()\n",
    "\n",
    "# Les ensembles sont les données complètes (T=2017)\n",
    "X_full = df_ml_pd.drop(columns=[cible_col, 'AnneeClotureExercice', 'siren']).fillna(0)\n",
    "y_full = df_ml_pd[cible_col]\n",
    "\n",
    "# Configuration de la Cross-Validation (Exigence du Professeur)\n",
    "# Nous utilisons 5 splits car nous n'avons pas assez de périodes pour TimeSeriesSplit.\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Définition des scoreurs\n",
    "scorer_rmse = make_scorer(mean_squared_error, squared=False)\n",
    "scorer_mae = make_scorer(mean_absolute_error)\n",
    "\n",
    "# Dictionnaire de suivi\n",
    "tracking_results: Dict[str, Dict[str, Any]] = {}\n",
    "\n",
    "print(f\"Jeu de données complet (T=2017 -> Y=2018) chargé. Taille: {X_full.shape[0]} observations.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 1. BASELINE (CV) --- RMSE: nan | MAE: 643,319.40\n"
     ]
    }
   ],
   "source": [
    "# --- 1. BASELINE (Linear Regression - Ratios T) ---\n",
    "features_baseline = [\n",
    "    \"ratio_rentabilite_nette\",\n",
    "    \"ratio_endettement\",\n",
    "    \"ratio_marge_brute\"\n",
    "]\n",
    "\n",
    "X_baseline = X_full[features_baseline]\n",
    "model_baseline = LinearRegression()\n",
    "\n",
    "# Calcul des scores par CV\n",
    "rmse_scores = cross_val_score(model_baseline, X_baseline, y_full, scoring=scorer_rmse, cv=kf)\n",
    "mae_scores = cross_val_score(model_baseline, X_baseline, y_full, scoring=scorer_mae, cv=kf)\n",
    "\n",
    "rmse_cv_baseline = np.mean(rmse_scores)\n",
    "mae_cv_baseline = np.mean(mae_scores)\n",
    "\n",
    "tracking_results['BASELINE'] = {\n",
    "    'Modèle': 'Linear Regression',\n",
    "    'Features': 'Ratios T seulement',\n",
    "    'RMSE_CV_Moyenne': rmse_cv_baseline,\n",
    "    'MAE_CV_Moyenne': mae_cv_baseline\n",
    "}\n",
    "\n",
    "print(f\"\\n--- 1. BASELINE (CV) --- RMSE: {rmse_cv_baseline:,.2f} | MAE: {mae_cv_baseline:,.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 2. ITÉRATION 1 (CV) --- RMSE: nan | MAE: 585,098.62\n"
     ]
    }
   ],
   "source": [
    "# --- 2. ITÉRATION 1 (Linear Regression - Ratios + Deltas) ---\n",
    "features_iteration_1 = features_baseline + [\n",
    "    \"delta_ResultatNet_1an\",\n",
    "    \"delta_CA_1an\",\n",
    "    \"ResultatNet_T_moins_1\",\n",
    "    \"CA_T_moins_1\"\n",
    "]\n",
    "\n",
    "X_iter_1 = X_full[features_iteration_1]\n",
    "model_iter_1 = LinearRegression()\n",
    "\n",
    "rmse_scores = cross_val_score(model_iter_1, X_iter_1, y_full, scoring=scorer_rmse, cv=kf)\n",
    "mae_scores = cross_val_score(model_iter_1, X_iter_1, y_full, scoring=scorer_mae, cv=kf)\n",
    "\n",
    "rmse_cv_iter_1 = np.mean(rmse_scores)\n",
    "mae_cv_iter_1 = np.mean(mae_scores)\n",
    "\n",
    "tracking_results['ITER_1'] = {\n",
    "    'Modèle': 'Linear Regression',\n",
    "    'Features': 'Ratios T + Deltas T-1',\n",
    "    'RMSE_CV_Moyenne': rmse_cv_iter_1,\n",
    "    'MAE_CV_Moyenne': mae_cv_iter_1\n",
    "}\n",
    "\n",
    "print(f\"--- 2. ITÉRATION 1 (CV) --- RMSE: {rmse_cv_iter_1:,.2f} | MAE: {mae_cv_iter_1:,.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 3. ITÉRATION 2 (CV) --- RMSE: nan | MAE: 585,098.62\n"
     ]
    }
   ],
   "source": [
    "# --- 3. ITÉRATION 2 (Linear Regression - Scaled Data) ---\n",
    "X_iter_2 = X_full[features_iteration_1]\n",
    "\n",
    "# La mise à l'échelle doit être intégrée dans un Pipeline pour la CV pour éviter le data leakage\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipeline_iter_2 = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('regressor', LinearRegression())\n",
    "])\n",
    "\n",
    "rmse_scores = cross_val_score(pipeline_iter_2, X_iter_2, y_full, scoring=scorer_rmse, cv=kf)\n",
    "mae_scores = cross_val_score(pipeline_iter_2, X_iter_2, y_full, scoring=scorer_mae, cv=kf)\n",
    "\n",
    "rmse_cv_iter_2 = np.mean(rmse_scores)\n",
    "mae_cv_iter_2 = np.mean(mae_scores)\n",
    "\n",
    "tracking_results['ITER_2'] = {\n",
    "    'Modèle': 'Linear Regression + Scaled',\n",
    "    'Features': 'Ratios T + Deltas T-1 (SCALÉS)',\n",
    "    'RMSE_CV_Moyenne': rmse_cv_iter_2,\n",
    "    'MAE_CV_Moyenne': mae_cv_iter_2\n",
    "}\n",
    "\n",
    "print(f\"--- 3. ITÉRATION 2 (CV) --- RMSE: {rmse_cv_iter_2:,.2f} | MAE: {mae_cv_iter_2:,.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 4. ITÉRATION 3 (CV) --- RMSE: nan | MAE: 563,600.62\n"
     ]
    }
   ],
   "source": [
    "# --- 4. ITÉRATION 3 (Random Forest Regressor) ---\n",
    "X_iter_3 = X_full[features_iteration_1]\n",
    "\n",
    "# Hyperparamètres simples (pas besoin de scaler)\n",
    "model_iter_3 = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1, max_depth=10)\n",
    "\n",
    "rmse_scores = cross_val_score(model_iter_3, X_iter_3, y_full, scoring=scorer_rmse, cv=kf)\n",
    "mae_scores = cross_val_score(model_iter_3, X_iter_3, y_full, scoring=scorer_mae, cv=kf)\n",
    "\n",
    "rmse_cv_iter_3 = np.mean(rmse_scores)\n",
    "mae_cv_iter_3 = np.mean(mae_scores)\n",
    "\n",
    "tracking_results['ITER_3'] = {\n",
    "    'Modèle': 'Random Forest Regressor',\n",
    "    'Features': 'Ratios T + Deltas T-1',\n",
    "    'RMSE_CV_Moyenne': rmse_cv_iter_3,\n",
    "    'MAE_CV_Moyenne': mae_cv_iter_3\n",
    "}\n",
    "\n",
    "print(f\"--- 4. ITÉRATION 3 (CV) --- RMSE: {rmse_cv_iter_3:,.2f} | MAE: {mae_cv_iter_3:,.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Synthèse des Expérimentations (Experimentation Tracking)\n",
      "==================================================\n",
      "|          | Modèle                     | Features                       |   RMSE_CV_Moyenne | MAE_CV_Moyenne   |\n",
      "|:---------|:---------------------------|:-------------------------------|------------------:|:-----------------|\n",
      "| BASELINE | Linear Regression          | Ratios T seulement             |               nan | 643,319.40       |\n",
      "| ITER_1   | Linear Regression          | Ratios T + Deltas T-1          |               nan | 585,098.62       |\n",
      "| ITER_2   | Linear Regression + Scaled | Ratios T + Deltas T-1 (SCALÉS) |               nan | 585,098.62       |\n",
      "| ITER_3   | Random Forest Regressor    | Ratios T + Deltas T-1          |               nan | 563,600.62       |\n",
      "\n",
      "Conclusion: Le meilleur modèle (basé sur le MAE) est l'ITER_3, qui est un modèle non-linéaire adapté à l'asymétrie des données financières.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Synthèse des Expérimentations (Experimentation Tracking)\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "df_tracking = pd.DataFrame(tracking_results).T\n",
    "df_tracking['RMSE_CV_Moyenne'] = df_tracking['RMSE_CV_Moyenne'].apply(lambda x: f'{x:,.2f}')\n",
    "df_tracking['MAE_CV_Moyenne'] = df_tracking['MAE_CV_Moyenne'].apply(lambda x: f'{x:,.2f}')\n",
    "\n",
    "print(df_tracking.to_markdown())\n",
    "\n",
    "# Le meilleur modèle est celui avec le MAE le plus faible.\n",
    "best_model_row = df_tracking['MAE_CV_Moyenne'].astype(str).str.replace(',', '').astype(float).idxmin()\n",
    "print(f\"\\nConclusion: Le meilleur modèle (basé sur le MAE) est l'{best_model_row}, qui est un modèle non-linéaire adapté à l'asymétrie des données financières.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Schema([('siren', String),\n",
       "        ('date_cloture_exercice', Date),\n",
       "        ('CJCK_TotalActifBrut', Int32),\n",
       "        ('EG_ImpotsTaxes', Int32),\n",
       "        ('FJ_ResultatFinancier', Int32),\n",
       "        ('FA_ChiffreAffairesVentes', Int32),\n",
       "        ('HN_RésultatNet', Int32),\n",
       "        ('DA_TresorerieActive', Int32),\n",
       "        ('DL_DettesCourtTerme', Int32),\n",
       "        ('FB_AchatsMarchandises', Int32),\n",
       "        ('FR_ResultatExceptionnel', Int32),\n",
       "        ('DF_CapitauxPropres', Int32),\n",
       "        ('DM_DettesLongTerme', Int32),\n",
       "        ('AnneeClotureExercice', Int32),\n",
       "        ('ratio_rentabilite_nette', Float64),\n",
       "        ('ratio_endettement', Float64),\n",
       "        ('ratio_marge_brute', Float64),\n",
       "        ('ratio_capitaux_propres', Float64),\n",
       "        ('ratio_tresorerie', Float64),\n",
       "        ('ratio_resultat_financier', Float64),\n",
       "        ('ratio_resultat_exceptionnel', Float64),\n",
       "        ('cible_HN_RésultatNet_T_plus_1', Int32),\n",
       "        ('ResultatNet_T_moins_1', Int32),\n",
       "        ('CA_T_moins_1', Int32),\n",
       "        ('ResultatNet_T_moins_2', Int32),\n",
       "        ('CA_T_moins_2', Int32),\n",
       "        ('delta_ResultatNet_1an', Int32),\n",
       "        ('delta_CA_1an', Int32),\n",
       "        ('delta_ResultatNet_2ans', Int32),\n",
       "        ('delta_CA_2ans', Int32)])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ml.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 3.1 Importance des Features (Top 5) ---\n",
      "HN_RésultatNet             0.199127\n",
      "ratio_rentabilite_nette    0.183555\n",
      "ResultatNet_T_moins_1      0.173644\n",
      "ResultatNet_T_moins_2      0.155053\n",
      "delta_ResultatNet_2ans     0.092726\n",
      "dtype: float64\n",
      "-----------------------------------\n",
      "\n",
      "--- 3.2 ITÉRATION 4 (Sélection de Features par RF) ---\n",
      "Features retenues : ['HN_RésultatNet', 'ratio_rentabilite_nette', 'ResultatNet_T_moins_1', 'ResultatNet_T_moins_2', 'delta_ResultatNet_2ans']\n",
      "RMSE (Moyenne CV, n=5) : nan\n",
      "MAE (Moyenne CV, n=5) : 527,764.89\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, make_scorer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "\n",
    "# --- 1. Définition du Jeu de Features Maximal (CORRIGÉ) ---\n",
    "# Liste exhaustive des features d'entrée (X) présentes dans le DataFrame X_full.\n",
    "# On exclut toutes les colonnes d'identifiant, de temps, et la cible qui ne sont plus dans X_full\n",
    "features_maximales = [\n",
    "    'CJCK_TotalActifBrut', 'EG_ImpotsTaxes', 'FJ_ResultatFinancier', \n",
    "    'FA_ChiffreAffairesVentes', 'HN_RésultatNet', 'DA_TresorerieActive', \n",
    "    'DL_DettesCourtTerme', 'FB_AchatsMarchandises', 'FR_ResultatExceptionnel', \n",
    "    'DF_CapitauxPropres', 'DM_DettesLongTerme', \n",
    "    \n",
    "    # Ratios T\n",
    "    'ratio_rentabilite_nette', 'ratio_endettement', 'ratio_marge_brute', \n",
    "    'ratio_capitaux_propres', 'ratio_tresorerie', 'ratio_resultat_financier', \n",
    "    'ratio_resultat_exceptionnel', \n",
    "    \n",
    "    # Features T-1 et T-2\n",
    "    'ResultatNet_T_moins_1', 'CA_T_moins_1', 'ResultatNet_T_moins_2', 'CA_T_moins_2', \n",
    "    \n",
    "    # Deltas\n",
    "    'delta_ResultatNet_1an', 'delta_CA_1an', 'delta_ResultatNet_2ans', \n",
    "    'delta_CA_2ans'\n",
    "]\n",
    "\n",
    "# On filtre l'ensemble X_full sur cette liste.\n",
    "# NOTE: Si X_full contient encore d'autres colonnes non listées, cette ligne peut échouer.\n",
    "X_full_max = X_full[features_maximales] \n",
    "\n",
    "\n",
    "# --- 2. Entraînement Initial pour l'Importance (Modèle de référence) ---\n",
    "model_importance = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1, max_depth=10)\n",
    "\n",
    "# Entraînement simple (sans CV) pour obtenir l'importance des features\n",
    "# On utilise ici l'ensemble X_full (T=2017) comme ensemble d'entraînement unique\n",
    "model_importance.fit(X_full_max, y_full)\n",
    "\n",
    "# --- 3. Sélection des Top 5 Features ---\n",
    "importances = model_importance.feature_importances_\n",
    "feature_series = pd.Series(importances, index=X_full_max.columns).sort_values(ascending=False)\n",
    "\n",
    "top_n = 5\n",
    "features_selectionnees = feature_series.head(top_n).index.tolist()\n",
    "\n",
    "print(\"\\n--- 3.1 Importance des Features (Top 5) ---\")\n",
    "print(feature_series.head(top_n))\n",
    "print(\"-\" * 35)\n",
    "\n",
    "\n",
    "# --- 4. Nouvel Entraînement avec les Features Sélectionnées (Itération 4) ---\n",
    "X_iter_4 = X_full[features_selectionnees] # Utilisation du sous-ensemble sélectionné\n",
    "\n",
    "# Modèle Random Forest final\n",
    "model_iter_4 = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1, max_depth=10)\n",
    "\n",
    "# Calcul des scores par Cross-Validation (CV)\n",
    "rmse_scores = cross_val_score(model_iter_4, X_iter_4, y_full, scoring=make_scorer(mean_squared_error, squared=False), cv=kf)\n",
    "mae_scores = cross_val_score(model_iter_4, X_iter_4, y_full, scoring=make_scorer(mean_absolute_error), cv=kf)\n",
    "\n",
    "rmse_cv_iter_4 = np.mean(rmse_scores)\n",
    "mae_cv_iter_4 = np.mean(mae_scores)\n",
    "\n",
    "# Documentation pour l'Experimentation Tracking\n",
    "tracking_results['ITER_4'] = {\n",
    "    'Modèle': 'Random Forest Regressor',\n",
    "    'Features': f'Sélection Top {top_n} : {features_selectionnees}',\n",
    "    'RMSE_CV_Moyenne': rmse_cv_iter_4,\n",
    "    'MAE_CV_Moyenne': mae_cv_iter_4\n",
    "}\n",
    "\n",
    "print(\"\\n--- 3.2 ITÉRATION 4 (Sélection de Features par RF) ---\")\n",
    "print(f\"Features retenues : {features_selectionnees}\")\n",
    "print(f\"RMSE (Moyenne CV, n=5) : {rmse_cv_iter_4:,.2f}\")\n",
    "print(f\"MAE (Moyenne CV, n=5) : {mae_cv_iter_4:,.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- ITÉRATION 5 (XGBoost - Sélection de Features) ---\n",
      "Features retenues : ['HN_RésultatNet', 'ratio_rentabilite_nette', 'ResultatNet_T_moins_1', 'ResultatNet_T_moins_2', 'delta_ResultatNet_2ans']\n",
      "RMSE (Moyenne CV, n=5) : nan\n",
      "MAE (Moyenne CV, n=5) : 569,748.17\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, make_scorer\n",
    "import xgboost as xgb # Nouvelle librairie !\n",
    "\n",
    "# Assurez-vous d'avoir installé xgboost : pip install xgboost\n",
    "\n",
    "# --- 1. Définition des Features Finales (Top 5 de l'Itération 4) ---\n",
    "features_selectionnees = ['HN_RésultatNet', 'ratio_rentabilite_nette', 'ResultatNet_T_moins_1', 'ResultatNet_T_moins_2', 'delta_ResultatNet_2ans']\n",
    "\n",
    "X_iter_5 = X_full[features_selectionnees] # Utilisation du sous-ensemble sélectionné\n",
    "y_full = y_full.astype(np.float64) # Conversion de la cible pour stabiliser le calcul\n",
    "\n",
    "# --- 2. Définition du Modèle et Hyperparamètres (XGBoost) ---\n",
    "# Modèle plus puissant\n",
    "model_iter_5 = xgb.XGBRegressor(\n",
    "    n_estimators=200,          # Plus d'arbres que le Random Forest\n",
    "    learning_rate=0.05,        # Taux d'apprentissage plus faible pour la précision\n",
    "    max_depth=6,               # Profondeur limitée\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# --- 3. Cross-Validation (CV) ---\n",
    "\n",
    "# Définition des scoreurs (conversion RMSE en float64 pour éviter le nan)\n",
    "# Nous convertissons les labels (y_full) et les prédictions dans le scoreur\n",
    "def safe_rmse_scorer(y_true, y_pred):\n",
    "    return mean_squared_error(y_true.astype(np.float64), y_pred.astype(np.float64), squared=False)\n",
    "\n",
    "scorer_rmse = make_scorer(safe_rmse_scorer)\n",
    "scorer_mae = make_scorer(mean_absolute_error)\n",
    "\n",
    "# Calcul des scores par CV\n",
    "rmse_scores = cross_val_score(model_iter_5, X_iter_5, y_full, scoring=scorer_rmse, cv=kf)\n",
    "mae_scores = cross_val_score(model_iter_5, X_iter_5, y_full, scoring=scorer_mae, cv=kf)\n",
    "\n",
    "rmse_cv_iter_5 = np.mean(rmse_scores)\n",
    "mae_cv_iter_5 = np.mean(mae_scores)\n",
    "\n",
    "# Documentation pour l'Experimentation Tracking\n",
    "tracking_results['ITER_5'] = {\n",
    "    'Modèle': 'XGBoost Regressor',\n",
    "    'Features': f'Top 5 : {features_selectionnees}',\n",
    "    'RMSE_CV_Moyenne': rmse_cv_iter_5,\n",
    "    'MAE_CV_Moyenne': mae_cv_iter_5\n",
    "}\n",
    "\n",
    "print(\"\\n--- ITÉRATION 5 (XGBoost - Sélection de Features) ---\")\n",
    "print(f\"Features retenues : {features_selectionnees}\")\n",
    "print(f\"RMSE (Moyenne CV, n=5) : {rmse_cv_iter_5:,.2f}\")\n",
    "print(f\"MAE (Moyenne CV, n=5) : {mae_cv_iter_5:,.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (9, 31)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>statistic</th><th>siren</th><th>date_cloture_exercice</th><th>CJCK_TotalActifBrut</th><th>EG_ImpotsTaxes</th><th>FJ_ResultatFinancier</th><th>FA_ChiffreAffairesVentes</th><th>HN_RésultatNet</th><th>DA_TresorerieActive</th><th>DL_DettesCourtTerme</th><th>FB_AchatsMarchandises</th><th>FR_ResultatExceptionnel</th><th>DF_CapitauxPropres</th><th>DM_DettesLongTerme</th><th>AnneeClotureExercice</th><th>ratio_rentabilite_nette</th><th>ratio_endettement</th><th>ratio_marge_brute</th><th>ratio_capitaux_propres</th><th>ratio_tresorerie</th><th>ratio_resultat_financier</th><th>ratio_resultat_exceptionnel</th><th>cible_HN_RésultatNet_T_plus_1</th><th>ResultatNet_T_moins_1</th><th>CA_T_moins_1</th><th>ResultatNet_T_moins_2</th><th>CA_T_moins_2</th><th>delta_ResultatNet_1an</th><th>delta_CA_1an</th><th>delta_ResultatNet_2ans</th><th>delta_CA_2ans</th></tr><tr><td>str</td><td>str</td><td>str</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>&quot;count&quot;</td><td>&quot;29960&quot;</td><td>&quot;29960&quot;</td><td>29960.0</td><td>29960.0</td><td>29960.0</td><td>29960.0</td><td>29960.0</td><td>29960.0</td><td>29960.0</td><td>29960.0</td><td>29960.0</td><td>29960.0</td><td>29960.0</td><td>29960.0</td><td>29960.0</td><td>29960.0</td><td>29960.0</td><td>29960.0</td><td>29960.0</td><td>29960.0</td><td>29960.0</td><td>29960.0</td><td>29960.0</td><td>29960.0</td><td>29960.0</td><td>29960.0</td><td>29960.0</td><td>29960.0</td><td>29960.0</td><td>29960.0</td></tr><tr><td>&quot;null_count&quot;</td><td>&quot;0&quot;</td><td>&quot;0&quot;</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><td>&quot;mean&quot;</td><td>null</td><td>&quot;2017-11-29 11:45:23.311081&quot;</td><td>3.7003e6</td><td>1.2217e6</td><td>4.0842e6</td><td>1.8822e6</td><td>307176.811048</td><td>1.3843e6</td><td>3.1835e6</td><td>209267.54002</td><td>6.2336e6</td><td>47519.787517</td><td>35374.448097</td><td>2017.0</td><td>2.3744e11</td><td>2.2456e11</td><td>-2.7344e10</td><td>3.1169e6</td><td>7.2426e10</td><td>1.3841e12</td><td>3.2273e12</td><td>317851.048131</td><td>282025.301802</td><td>1.8344e6</td><td>90660.980808</td><td>1.8390e6</td><td>25151.509246</td><td>47803.595728</td><td>216515.83024</td><td>43184.551035</td></tr><tr><td>&quot;std&quot;</td><td>null</td><td>null</td><td>3.7960e7</td><td>1.4049e7</td><td>4.4543e7</td><td>3.5209e7</td><td>1.4429e7</td><td>2.7779e7</td><td>5.2402e7</td><td>6.4919e6</td><td>6.1211e7</td><td>4.9262e6</td><td>3.3990e6</td><td>0.0</td><td>1.4219e13</td><td>1.9155e13</td><td>2.3826e12</td><td>5.3411e8</td><td>6.6289e12</td><td>1.8111e13</td><td>4.4390e13</td><td>1.1499e7</td><td>1.4822e7</td><td>3.3521e7</td><td>1.8062e7</td><td>3.3461e7</td><td>9.8418e6</td><td>7.7639e6</td><td>2.1025e7</td><td>7.7876e6</td></tr><tr><td>&quot;min&quot;</td><td>&quot;005450119&quot;</td><td>&quot;2017-01-01&quot;</td><td>-664170.0</td><td>-1.256488e6</td><td>-1.13937e6</td><td>-78658.0</td><td>-2.8186e8</td><td>-2.1473e9</td><td>-2.1475e9</td><td>-111906.0</td><td>-1.8326e9</td><td>0.0</td><td>0.0</td><td>2017.0</td><td>-2.8186e14</td><td>-7.9900e14</td><td>-3.9829e14</td><td>0.0</td><td>-929.977761</td><td>-1.1394e12</td><td>-1.2480e15</td><td>-2.6755e8</td><td>-9.6940e8</td><td>-543000.0</td><td>-1.8557e9</td><td>-7.975916e6</td><td>-5.5641e8</td><td>-3.0365e8</td><td>-1.0624e9</td><td>-2.5383e8</td></tr><tr><td>&quot;25%&quot;</td><td>null</td><td>&quot;2017-12-31&quot;</td><td>120419.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>7622.0</td><td>38102.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>2017.0</td><td>0.0</td><td>0.200536</td><td>0.0</td><td>0.0</td><td>0.023534</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>-1134.0</td><td>0.0</td><td>-17059.0</td><td>0.0</td><td>-29337.0</td><td>0.0</td></tr><tr><td>&quot;50%&quot;</td><td>null</td><td>&quot;2017-12-31&quot;</td><td>449449.0</td><td>114133.0</td><td>145561.0</td><td>0.0</td><td>6111.0</td><td>30500.0</td><td>241807.0</td><td>0.0</td><td>285295.0</td><td>0.0</td><td>0.0</td><td>2017.0</td><td>0.060985</td><td>0.55947</td><td>0.0</td><td>0.0</td><td>0.081759</td><td>1.295581</td><td>1.9400e9</td><td>3583.0</td><td>7239.0</td><td>0.0</td><td>10486.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><td>&quot;75%&quot;</td><td>null</td><td>&quot;2017-12-31&quot;</td><td>1.374439e6</td><td>537141.0</td><td>1.112941e6</td><td>0.0</td><td>73391.0</td><td>152400.0</td><td>823346.0</td><td>0.0</td><td>1.51484e6</td><td>0.0</td><td>0.0</td><td>2017.0</td><td>2.9446e10</td><td>0.99239</td><td>0.0</td><td>0.0</td><td>0.308944</td><td>2.6064e11</td><td>5.2351e11</td><td>69854.0</td><td>69804.0</td><td>51.0</td><td>72542.0</td><td>10066.0</td><td>24948.0</td><td>0.0</td><td>38269.0</td><td>0.0</td></tr><tr><td>&quot;max&quot;</td><td>&quot;998620116&quot;</td><td>&quot;2017-12-31&quot;</td><td>2.1475e9</td><td>1.5077e9</td><td>2.1475e9</td><td>2.1475e9</td><td>1.9240e9</td><td>1.5642e9</td><td>2.1475e9</td><td>6.32981128e8</td><td>2.1475e9</td><td>8.29010242e8</td><td>3.9498e8</td><td>2017.0</td><td>1.9240e15</td><td>2.1475e15</td><td>3.1421e10</td><td>9.2447e10</td><td>9.8000e14</td><td>1.6878e15</td><td>2.1475e15</td><td>1.5910e9</td><td>2.1475e9</td><td>2.1475e9</td><td>1.0574e9</td><td>2.1475e9</td><td>1.0939e9</td><td>1.0405e9</td><td>1.9359e9</td><td>1.0300e9</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (9, 31)\n",
       "┌───────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬──────────┐\n",
       "│ statistic ┆ siren     ┆ date_clot ┆ CJCK_Tota ┆ … ┆ delta_Res ┆ delta_CA_ ┆ delta_Res ┆ delta_CA │\n",
       "│ ---       ┆ ---       ┆ ure_exerc ┆ lActifBru ┆   ┆ ultatNet_ ┆ 1an       ┆ ultatNet_ ┆ _2ans    │\n",
       "│ str       ┆ str       ┆ ice       ┆ t         ┆   ┆ 1an       ┆ ---       ┆ 2ans      ┆ ---      │\n",
       "│           ┆           ┆ ---       ┆ ---       ┆   ┆ ---       ┆ f64       ┆ ---       ┆ f64      │\n",
       "│           ┆           ┆ str       ┆ f64       ┆   ┆ f64       ┆           ┆ f64       ┆          │\n",
       "╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪══════════╡\n",
       "│ count     ┆ 29960     ┆ 29960     ┆ 29960.0   ┆ … ┆ 29960.0   ┆ 29960.0   ┆ 29960.0   ┆ 29960.0  │\n",
       "│ null_coun ┆ 0         ┆ 0         ┆ 0.0       ┆ … ┆ 0.0       ┆ 0.0       ┆ 0.0       ┆ 0.0      │\n",
       "│ t         ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ mean      ┆ null      ┆ 2017-11-2 ┆ 3.7003e6  ┆ … ┆ 25151.509 ┆ 47803.595 ┆ 216515.83 ┆ 43184.55 │\n",
       "│           ┆           ┆ 9 11:45:2 ┆           ┆   ┆ 246       ┆ 728       ┆ 024       ┆ 1035     │\n",
       "│           ┆           ┆ 3.311081  ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ std       ┆ null      ┆ null      ┆ 3.7960e7  ┆ … ┆ 9.8418e6  ┆ 7.7639e6  ┆ 2.1025e7  ┆ 7.7876e6 │\n",
       "│ min       ┆ 005450119 ┆ 2017-01-0 ┆ -664170.0 ┆ … ┆ -5.5641e8 ┆ -3.0365e8 ┆ -1.0624e9 ┆ -2.5383e │\n",
       "│           ┆           ┆ 1         ┆           ┆   ┆           ┆           ┆           ┆ 8        │\n",
       "│ 25%       ┆ null      ┆ 2017-12-3 ┆ 120419.0  ┆ … ┆ -17059.0  ┆ 0.0       ┆ -29337.0  ┆ 0.0      │\n",
       "│           ┆           ┆ 1         ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 50%       ┆ null      ┆ 2017-12-3 ┆ 449449.0  ┆ … ┆ 0.0       ┆ 0.0       ┆ 0.0       ┆ 0.0      │\n",
       "│           ┆           ┆ 1         ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 75%       ┆ null      ┆ 2017-12-3 ┆ 1.374439e ┆ … ┆ 24948.0   ┆ 0.0       ┆ 38269.0   ┆ 0.0      │\n",
       "│           ┆           ┆ 1         ┆ 6         ┆   ┆           ┆           ┆           ┆          │\n",
       "│ max       ┆ 998620116 ┆ 2017-12-3 ┆ 2.1475e9  ┆ … ┆ 1.0939e9  ┆ 1.0405e9  ┆ 1.9359e9  ┆ 1.0300e9 │\n",
       "│           ┆           ┆ 1         ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "└───────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴──────────┘"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ml.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Démarrage de l'Itération 1 (XGBoost / 23 features) avec Cross-Validation...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot have number of splits n_splits=5 greater than the number of samples: n_samples=0.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[27]\u001b[39m\u001b[32m, line 65\u001b[39m\n\u001b[32m     62\u001b[39m \u001b[38;5;66;03m# --- 3. Calcul des Scores par Cross-Validation (CV) ---\u001b[39;00m\n\u001b[32m     63\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mDémarrage de l\u001b[39m\u001b[33m'\u001b[39m\u001b[33mItération 1 (XGBoost / \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(features_maximales)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m features) avec Cross-Validation...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m65\u001b[39m rmse_scores = \u001b[43mcross_val_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_xgb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_full\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_full\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscoring\u001b[49m\u001b[43m=\u001b[49m\u001b[43mscorer_rmse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     66\u001b[39m mae_scores = cross_val_score(model_xgb, X_full, y_full, scoring=scorer_mae, cv=kf)\n\u001b[32m     68\u001b[39m rmse_cv_iter_1 = np.mean(rmse_scores)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Cours/Master/Cours/M1/Supervised Learning/Final Project/.venv/lib/python3.14/site-packages/sklearn/utils/_param_validation.py:218\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    212\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    213\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m    214\u001b[39m         skip_parameter_validation=(\n\u001b[32m    215\u001b[39m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m    216\u001b[39m         )\n\u001b[32m    217\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m218\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    220\u001b[39m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[32m    222\u001b[39m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[32m    224\u001b[39m     msg = re.sub(\n\u001b[32m    225\u001b[39m         \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[33m\\\u001b[39m\u001b[33mw+ must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    226\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    227\u001b[39m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[32m    228\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Cours/Master/Cours/M1/Supervised Learning/Final Project/.venv/lib/python3.14/site-packages/sklearn/model_selection/_validation.py:677\u001b[39m, in \u001b[36mcross_val_score\u001b[39m\u001b[34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, params, pre_dispatch, error_score)\u001b[39m\n\u001b[32m    674\u001b[39m \u001b[38;5;66;03m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[32m    675\u001b[39m scorer = check_scoring(estimator, scoring=scoring)\n\u001b[32m--> \u001b[39m\u001b[32m677\u001b[39m cv_results = \u001b[43mcross_validate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    678\u001b[39m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m=\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    679\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    680\u001b[39m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m=\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    681\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    682\u001b[39m \u001b[43m    \u001b[49m\u001b[43mscoring\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mscore\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    683\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcv\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    684\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    685\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    686\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    687\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpre_dispatch\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpre_dispatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    688\u001b[39m \u001b[43m    \u001b[49m\u001b[43merror_score\u001b[49m\u001b[43m=\u001b[49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    689\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    690\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m cv_results[\u001b[33m\"\u001b[39m\u001b[33mtest_score\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Cours/Master/Cours/M1/Supervised Learning/Final Project/.venv/lib/python3.14/site-packages/sklearn/utils/_param_validation.py:218\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    212\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    213\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m    214\u001b[39m         skip_parameter_validation=(\n\u001b[32m    215\u001b[39m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m    216\u001b[39m         )\n\u001b[32m    217\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m218\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    220\u001b[39m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[32m    222\u001b[39m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[32m    224\u001b[39m     msg = re.sub(\n\u001b[32m    225\u001b[39m         \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[33m\\\u001b[39m\u001b[33mw+ must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    226\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    227\u001b[39m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[32m    228\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Cours/Master/Cours/M1/Supervised Learning/Final Project/.venv/lib/python3.14/site-packages/sklearn/model_selection/_validation.py:399\u001b[39m, in \u001b[36mcross_validate\u001b[39m\u001b[34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001b[39m\n\u001b[32m    396\u001b[39m \u001b[38;5;66;03m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[32m    397\u001b[39m \u001b[38;5;66;03m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[32m    398\u001b[39m parallel = Parallel(n_jobs=n_jobs, verbose=verbose, pre_dispatch=pre_dispatch)\n\u001b[32m--> \u001b[39m\u001b[32m399\u001b[39m results = \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    400\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    401\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    402\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    403\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    404\u001b[39m \u001b[43m        \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mscorers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    405\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    406\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    407\u001b[39m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    408\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    409\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    410\u001b[39m \u001b[43m        \u001b[49m\u001b[43mscore_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mscore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    411\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_train_score\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_train_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    412\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_times\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    413\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_estimator\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_estimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    414\u001b[39m \u001b[43m        \u001b[49m\u001b[43merror_score\u001b[49m\u001b[43m=\u001b[49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    415\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    416\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\n\u001b[32m    417\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    419\u001b[39m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[32m    421\u001b[39m \u001b[38;5;66;03m# For callable scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[32m    422\u001b[39m \u001b[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[32m    423\u001b[39m \u001b[38;5;66;03m# the correct key.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Cours/Master/Cours/M1/Supervised Learning/Final Project/.venv/lib/python3.14/site-packages/sklearn/utils/parallel.py:82\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m     73\u001b[39m warning_filters = warnings.filters\n\u001b[32m     74\u001b[39m iterable_with_config_and_warning_filters = (\n\u001b[32m     75\u001b[39m     (\n\u001b[32m     76\u001b[39m         _with_config_and_warning_filters(delayed_func, config, warning_filters),\n\u001b[32m   (...)\u001b[39m\u001b[32m     80\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[32m     81\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config_and_warning_filters\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Cours/Master/Cours/M1/Supervised Learning/Final Project/.venv/lib/python3.14/site-packages/joblib/parallel.py:1986\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   1984\u001b[39m     output = \u001b[38;5;28mself\u001b[39m._get_sequential_output(iterable)\n\u001b[32m   1985\u001b[39m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m1986\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1988\u001b[39m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[32m   1989\u001b[39m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[32m   1990\u001b[39m \u001b[38;5;66;03m# reused, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[32m   1991\u001b[39m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[32m   1992\u001b[39m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[32m   1993\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._lock:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Cours/Master/Cours/M1/Supervised Learning/Final Project/.venv/lib/python3.14/site-packages/joblib/parallel.py:1911\u001b[39m, in \u001b[36mParallel._get_sequential_output\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   1908\u001b[39m \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1910\u001b[39m \u001b[38;5;66;03m# Sequentially call the tasks and yield the results.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1911\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1912\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mn_dispatched_batches\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\n\u001b[32m   1913\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mn_dispatched_tasks\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Cours/Master/Cours/M1/Supervised Learning/Final Project/.venv/lib/python3.14/site-packages/sklearn/utils/parallel.py:80\u001b[39m, in \u001b[36m<genexpr>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m     72\u001b[39m config = get_config()\n\u001b[32m     73\u001b[39m warning_filters = warnings.filters\n\u001b[32m     74\u001b[39m iterable_with_config_and_warning_filters = \u001b[43m(\u001b[49m\n\u001b[32m     75\u001b[39m \u001b[43m    \u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     76\u001b[39m \u001b[43m        \u001b[49m\u001b[43m_with_config_and_warning_filters\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdelayed_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwarning_filters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     77\u001b[39m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     78\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     79\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m---> \u001b[39m\u001b[32m80\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdelayed_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\n\u001b[32m     81\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     82\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().\u001b[34m__call__\u001b[39m(iterable_with_config_and_warning_filters)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Cours/Master/Cours/M1/Supervised Learning/Final Project/.venv/lib/python3.14/site-packages/sklearn/model_selection/_validation.py:416\u001b[39m, in \u001b[36m<genexpr>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m    396\u001b[39m \u001b[38;5;66;03m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[32m    397\u001b[39m \u001b[38;5;66;03m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[32m    398\u001b[39m parallel = Parallel(n_jobs=n_jobs, verbose=verbose, pre_dispatch=pre_dispatch)\n\u001b[32m    399\u001b[39m results = parallel\u001b[43m(\u001b[49m\n\u001b[32m    400\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    401\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    402\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    403\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    404\u001b[39m \u001b[43m        \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mscorers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    405\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    406\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    407\u001b[39m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    408\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    409\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    410\u001b[39m \u001b[43m        \u001b[49m\u001b[43mscore_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mscore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    411\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_train_score\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_train_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    412\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_times\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    413\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_estimator\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_estimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    414\u001b[39m \u001b[43m        \u001b[49m\u001b[43merror_score\u001b[49m\u001b[43m=\u001b[49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    415\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m--> \u001b[39m\u001b[32m416\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\n\u001b[32m    417\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    419\u001b[39m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[32m    421\u001b[39m \u001b[38;5;66;03m# For callable scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[32m    422\u001b[39m \u001b[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[32m    423\u001b[39m \u001b[38;5;66;03m# the correct key.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Cours/Master/Cours/M1/Supervised Learning/Final Project/.venv/lib/python3.14/site-packages/sklearn/model_selection/_split.py:404\u001b[39m, in \u001b[36m_BaseKFold.split\u001b[39m\u001b[34m(self, X, y, groups)\u001b[39m\n\u001b[32m    402\u001b[39m n_samples = _num_samples(X)\n\u001b[32m    403\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.n_splits > n_samples:\n\u001b[32m--> \u001b[39m\u001b[32m404\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    405\u001b[39m         (\n\u001b[32m    406\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mCannot have number of splits n_splits=\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[33m greater\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    407\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33m than the number of samples: n_samples=\u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    408\u001b[39m         ).format(\u001b[38;5;28mself\u001b[39m.n_splits, n_samples)\n\u001b[32m    409\u001b[39m     )\n\u001b[32m    411\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m train, test \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().split(X, y, groups):\n\u001b[32m    412\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m train, test\n",
      "\u001b[31mValueError\u001b[39m: Cannot have number of splits n_splits=5 greater than the number of samples: n_samples=0."
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, make_scorer\n",
    "import numpy as np\n",
    "import warnings\n",
    "from typing import Dict, Any\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# --- 0. Chargement des Données et Préparation ---\n",
    "FILE_PATH_ML = \"../Data/processed/sirene_bilan_ML_prets.parquet\" \n",
    "cible_col = \"cible_HN_RésultatNet_T_plus_1\"\n",
    "\n",
    "try:\n",
    "    df_ml = pl.read_parquet(FILE_PATH_ML)\n",
    "except Exception as e:\n",
    "    print(f\"ERREUR : Impossible de charger le fichier ML. Vérifiez le chemin : {FILE_PATH_ML}\")\n",
    "    raise\n",
    "\n",
    "df_ml_pd = df_ml.to_pandas()\n",
    "\n",
    "# Définition de l'ensemble X et Y\n",
    "# On utilise la cible comme float64 pour éviter les erreurs d'overflow RMSE\n",
    "y_full = df_ml_pd[cible_col].astype(np.float64) \n",
    "\n",
    "# Liste exhaustive des features d'entrée (X)\n",
    "features_maximales = [\n",
    "    'CJCK_TotalActifBrut', 'EG_ImpotsTaxes', 'FJ_ResultatFinancier', 'FA_ChiffreAffairesVentes', \n",
    "    'HN_RésultatNet', 'DA_TresorerieActive', 'DL_DettesCourtTerme', 'FB_AchatsMarchandises', \n",
    "    'FR_ResultatExceptionnel', 'DF_CapitauxPropres', 'DM_DettesLongTerme', 'AnneeClotureExercice', \n",
    "    'ratio_rentabilite_nette', 'ratio_endettement', 'ratio_marge_brute', 'ratio_capitaux_propres', \n",
    "    'ratio_tresorerie', 'ratio_resultat_financier', 'ratio_resultat_exceptionnel', \n",
    "    'ResultatNet_T_moins_1', 'CA_T_moins_1','delta_ResultatNet_1an', 'delta_CA_1an'\n",
    "]\n",
    "X_full = df_ml_pd[features_maximales].fillna(0) # Imputation simple des NaNs avant le modèle\n",
    "\n",
    "# --- 1. Configuration de la Cross-Validation (CV) ---\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Définition des scoreurs (avec correction du type pour le RMSE)\n",
    "def safe_rmse_scorer(y_true, y_pred):\n",
    "    return mean_squared_error(y_true.astype(np.float64), y_pred.astype(np.float64), squared=False)\n",
    "\n",
    "scorer_rmse = make_scorer(safe_rmse_scorer)\n",
    "scorer_mae = make_scorer(mean_absolute_error)\n",
    "\n",
    "# --- 2. Modèle XGBoost (Hyperparamètres agressifs) ---\n",
    "model_xgb = xgb.XGBRegressor(\n",
    "    n_estimators=300,            # Beaucoup d'arbres\n",
    "    learning_rate=0.03,          # Petit pas d'apprentissage pour plus de précision\n",
    "    max_depth=7,                 # Profondeur suffisante\n",
    "    subsample=0.7,               # Utiliser un sous-échantillon des lignes (pour la robustesse)\n",
    "    colsample_bytree=0.7,        # Utiliser un sous-échantillon des colonnes (pour la robustesse)\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    tree_method='hist'           # Améliore la vitesse\n",
    ")\n",
    "\n",
    "# --- 3. Calcul des Scores par Cross-Validation (CV) ---\n",
    "print(f\"Démarrage de l'Itération 1 (XGBoost / {len(features_maximales)} features) avec Cross-Validation...\")\n",
    "\n",
    "rmse_scores = cross_val_score(model_xgb, X_full, y_full, scoring=scorer_rmse, cv=kf)\n",
    "mae_scores = cross_val_score(model_xgb, X_full, y_full, scoring=scorer_mae, cv=kf)\n",
    "\n",
    "rmse_cv_iter_1 = np.mean(rmse_scores)\n",
    "mae_cv_iter_1 = np.mean(mae_scores)\n",
    "\n",
    "# --- 4. Affichage du Résultat ---\n",
    "tracking_results = {\n",
    "    'ITER_1_AGRESSIVE': {\n",
    "        'Modèle': 'XGBoost Regressor',\n",
    "        'Features': f'Maximales (N={len(features_maximales)} features)',\n",
    "        'RMSE_CV_Moyenne': rmse_cv_iter_1,\n",
    "        'MAE_CV_Moyenne': mae_cv_iter_1\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"\\n--- ITÉRATION 1 (XGBoost Max Features) ---\")\n",
    "print(f\"RMSE (Moyenne CV, n=5) : {rmse_cv_iter_1:,.2f}\")\n",
    "print(f\"MAE (Moyenne CV, n=5) : {mae_cv_iter_1:,.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "date_cloture_exercice",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "CJCK_TotalActifBrut",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "EG_ImpotsTaxes",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "FJ_ResultatFinancier",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "FA_ChiffreAffairesVentes",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "HN_RésultatNet",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "DA_TresorerieActive",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "DL_DettesCourtTerme",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "FB_AchatsMarchandises",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "FR_ResultatExceptionnel",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "DF_CapitauxPropres",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "DM_DettesLongTerme",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "AnneeClotureExercice",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "ratio_rentabilite_nette",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "ratio_endettement",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "ratio_marge_brute",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "ratio_capitaux_propres",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "ratio_tresorerie",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "ratio_resultat_financier",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "ratio_resultat_exceptionnel",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "cible_HN_RésultatNet_T_plus_1",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "ResultatNet_T_moins_1",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "CA_T_moins_1",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "ResultatNet_T_moins_2",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "CA_T_moins_2",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "delta_ResultatNet_1an",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "delta_CA_1an",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "delta_ResultatNet_2ans",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "delta_CA_2ans",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "74637790-c0e5-4a93-a199-1c6fe7fa40df",
       "rows": [
        [
         "count",
         "29960",
         "29960.0",
         "29960.0",
         "29960.0",
         "29960.0",
         "29960.0",
         "29960.0",
         "29960.0",
         "29960.0",
         "29960.0",
         "29960.0",
         "29960.0",
         "29960.0",
         "29960.0",
         "29960.0",
         "29960.0",
         "29960.0",
         "29960.0",
         "29960.0",
         "29960.0",
         "29960.0",
         "29960.0",
         "29960.0",
         "29960.0",
         "29960.0",
         "29960.0",
         "29960.0",
         "29960.0",
         "29960.0"
        ],
        [
         "mean",
         "2017-11-29 11:45:23.311000",
         "3700343.433845127",
         "1221732.9943925233",
         "4084170.9898865153",
         "1882187.139185581",
         "307176.8110480641",
         "1384348.671929239",
         "3183491.715787717",
         "209267.5400200267",
         "6233579.164986649",
         "47519.78751668892",
         "35374.44809746328",
         "2017.0",
         "237444994841.78323",
         "224556674961.86923",
         "-27344399634.215424",
         "3116889.204774315",
         "72425794695.31255",
         "1384121503135.6199",
         "3227331817577.5137",
         "317851.0481308411",
         "282025.3018024032",
         "1834383.543457944",
         "90660.98080774366",
         "1839002.5881508677",
         "25151.50924566088",
         "47803.59572763685",
         "216515.8302403204",
         "43184.55103471295"
        ],
        [
         "min",
         "2017-01-01 00:00:00",
         "-664170.0",
         "-1256488.0",
         "-1139370.0",
         "-78658.0",
         "-281863940.0",
         "-2147318649.0",
         "-2147474099.0",
         "-111906.0",
         "-1832626649.0",
         "0.0",
         "0.0",
         "2017.0",
         "-281863940000000.0",
         "-799000000000000.0",
         "-398293011000000.0",
         "-0.0",
         "-929.9777605019793",
         "-1139370000000.0",
         "-1248037649000000.0",
         "-267552970.0",
         "-969403005.0",
         "-543000.0",
         "-1855683976.0",
         "-7975916.0",
         "-556405745.0",
         "-303651071.0",
         "-1062434910.0",
         "-253831000.0"
        ],
        [
         "25%",
         "2017-12-31 00:00:00",
         "120417.75",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "7622.0",
         "38099.25",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "2017.0",
         "0.0",
         "0.20051735270042445",
         "0.0",
         "0.0",
         "0.02353309080584407",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "-1135.75",
         "0.0",
         "-17059.5",
         "0.0",
         "-29338.25",
         "0.0"
        ],
        [
         "50%",
         "2017-12-31 00:00:00",
         "449434.0",
         "114116.5",
         "145550.0",
         "0.0",
         "6111.0",
         "30500.0",
         "241774.5",
         "0.0",
         "285292.0",
         "0.0",
         "0.0",
         "2017.0",
         "0.06096392002410904",
         "0.559456819141144",
         "0.0",
         "0.0",
         "0.08175625158365854",
         "1.295540213157634",
         "1922000000.0",
         "3582.5",
         "7237.0",
         "0.0",
         "10484.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "75%",
         "2017-12-31 00:00:00",
         "1374461.25",
         "537169.75",
         "1112943.0",
         "0.0",
         "73393.25",
         "152400.0",
         "823358.75",
         "0.0",
         "1515148.0",
         "0.0",
         "0.0",
         "2017.0",
         "29446750000.0",
         "0.9924043088171903",
         "0.0",
         "0.0",
         "0.3089736058014135",
         "260681500000.0",
         "523520500000.0",
         "69861.75",
         "69804.5",
         "51.5",
         "72542.75",
         "10067.25",
         "24948.0",
         "0.0",
         "38273.0",
         "0.0"
        ],
        [
         "max",
         "2017-12-31 00:00:00",
         "2147483647.0",
         "1507690165.0",
         "2147483647.0",
         "2147483647.0",
         "1924000000.0",
         "1564155438.0",
         "2147483647.0",
         "632981128.0",
         "2147483647.0",
         "829010242.0",
         "394980000.0",
         "2017.0",
         "1924000000000000.0",
         "2147483647000000.0",
         "31421000000.0",
         "92447000000.0",
         "980001000000000.0",
         "1687770078000000.0",
         "2147483647000000.0",
         "1591000000.0",
         "2147483647.0",
         "2147483647.0",
         "1057350175.0",
         "2147483647.0",
         "1093915401.0",
         "1040539532.0",
         "1935943356.0",
         "1030013521.0"
        ],
        [
         "std",
         null,
         "37960470.83507186",
         "14049403.152234962",
         "44542651.32572256",
         "35209022.62105241",
         "14429254.049298717",
         "27778785.609498657",
         "52402467.37185533",
         "6491862.031953515",
         "61211424.948360965",
         "4926165.810217405",
         "3398980.4619455254",
         "0.0",
         "14218852347979.678",
         "19154805340742.027",
         "2382616207143.7007",
         "534113177.5505464",
         "6628874771461.346",
         "18111478625291.152",
         "44390133867299.44",
         "11499178.146732802",
         "14821549.55910862",
         "33520613.066205397",
         "18061969.070533697",
         "33461052.778610833",
         "9841849.011503512",
         "7763924.643242333",
         "21025456.45879278",
         "7787572.175267208"
        ]
       ],
       "shape": {
        "columns": 29,
        "rows": 8
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_cloture_exercice</th>\n",
       "      <th>CJCK_TotalActifBrut</th>\n",
       "      <th>EG_ImpotsTaxes</th>\n",
       "      <th>FJ_ResultatFinancier</th>\n",
       "      <th>FA_ChiffreAffairesVentes</th>\n",
       "      <th>HN_RésultatNet</th>\n",
       "      <th>DA_TresorerieActive</th>\n",
       "      <th>DL_DettesCourtTerme</th>\n",
       "      <th>FB_AchatsMarchandises</th>\n",
       "      <th>FR_ResultatExceptionnel</th>\n",
       "      <th>...</th>\n",
       "      <th>ratio_resultat_exceptionnel</th>\n",
       "      <th>cible_HN_RésultatNet_T_plus_1</th>\n",
       "      <th>ResultatNet_T_moins_1</th>\n",
       "      <th>CA_T_moins_1</th>\n",
       "      <th>ResultatNet_T_moins_2</th>\n",
       "      <th>CA_T_moins_2</th>\n",
       "      <th>delta_ResultatNet_1an</th>\n",
       "      <th>delta_CA_1an</th>\n",
       "      <th>delta_ResultatNet_2ans</th>\n",
       "      <th>delta_CA_2ans</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>29960</td>\n",
       "      <td>2.996000e+04</td>\n",
       "      <td>2.996000e+04</td>\n",
       "      <td>2.996000e+04</td>\n",
       "      <td>2.996000e+04</td>\n",
       "      <td>2.996000e+04</td>\n",
       "      <td>2.996000e+04</td>\n",
       "      <td>2.996000e+04</td>\n",
       "      <td>2.996000e+04</td>\n",
       "      <td>2.996000e+04</td>\n",
       "      <td>...</td>\n",
       "      <td>2.996000e+04</td>\n",
       "      <td>2.996000e+04</td>\n",
       "      <td>2.996000e+04</td>\n",
       "      <td>2.996000e+04</td>\n",
       "      <td>2.996000e+04</td>\n",
       "      <td>2.996000e+04</td>\n",
       "      <td>2.996000e+04</td>\n",
       "      <td>2.996000e+04</td>\n",
       "      <td>2.996000e+04</td>\n",
       "      <td>2.996000e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2017-11-29 11:45:23.311000</td>\n",
       "      <td>3.700343e+06</td>\n",
       "      <td>1.221733e+06</td>\n",
       "      <td>4.084171e+06</td>\n",
       "      <td>1.882187e+06</td>\n",
       "      <td>3.071768e+05</td>\n",
       "      <td>1.384349e+06</td>\n",
       "      <td>3.183492e+06</td>\n",
       "      <td>2.092675e+05</td>\n",
       "      <td>6.233579e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>3.227332e+12</td>\n",
       "      <td>3.178510e+05</td>\n",
       "      <td>2.820253e+05</td>\n",
       "      <td>1.834384e+06</td>\n",
       "      <td>9.066098e+04</td>\n",
       "      <td>1.839003e+06</td>\n",
       "      <td>2.515151e+04</td>\n",
       "      <td>4.780360e+04</td>\n",
       "      <td>2.165158e+05</td>\n",
       "      <td>4.318455e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2017-01-01 00:00:00</td>\n",
       "      <td>-6.641700e+05</td>\n",
       "      <td>-1.256488e+06</td>\n",
       "      <td>-1.139370e+06</td>\n",
       "      <td>-7.865800e+04</td>\n",
       "      <td>-2.818639e+08</td>\n",
       "      <td>-2.147319e+09</td>\n",
       "      <td>-2.147474e+09</td>\n",
       "      <td>-1.119060e+05</td>\n",
       "      <td>-1.832627e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.248038e+15</td>\n",
       "      <td>-2.675530e+08</td>\n",
       "      <td>-9.694030e+08</td>\n",
       "      <td>-5.430000e+05</td>\n",
       "      <td>-1.855684e+09</td>\n",
       "      <td>-7.975916e+06</td>\n",
       "      <td>-5.564057e+08</td>\n",
       "      <td>-3.036511e+08</td>\n",
       "      <td>-1.062435e+09</td>\n",
       "      <td>-2.538310e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2017-12-31 00:00:00</td>\n",
       "      <td>1.204178e+05</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>7.622000e+03</td>\n",
       "      <td>3.809925e+04</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-1.135750e+03</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-1.705950e+04</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-2.933825e+04</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2017-12-31 00:00:00</td>\n",
       "      <td>4.494340e+05</td>\n",
       "      <td>1.141165e+05</td>\n",
       "      <td>1.455500e+05</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>6.111000e+03</td>\n",
       "      <td>3.050000e+04</td>\n",
       "      <td>2.417745e+05</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.852920e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>1.922000e+09</td>\n",
       "      <td>3.582500e+03</td>\n",
       "      <td>7.237000e+03</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.048400e+04</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2017-12-31 00:00:00</td>\n",
       "      <td>1.374461e+06</td>\n",
       "      <td>5.371698e+05</td>\n",
       "      <td>1.112943e+06</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>7.339325e+04</td>\n",
       "      <td>1.524000e+05</td>\n",
       "      <td>8.233588e+05</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.515148e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>5.235205e+11</td>\n",
       "      <td>6.986175e+04</td>\n",
       "      <td>6.980450e+04</td>\n",
       "      <td>5.150000e+01</td>\n",
       "      <td>7.254275e+04</td>\n",
       "      <td>1.006725e+04</td>\n",
       "      <td>2.494800e+04</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.827300e+04</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2017-12-31 00:00:00</td>\n",
       "      <td>2.147484e+09</td>\n",
       "      <td>1.507690e+09</td>\n",
       "      <td>2.147484e+09</td>\n",
       "      <td>2.147484e+09</td>\n",
       "      <td>1.924000e+09</td>\n",
       "      <td>1.564155e+09</td>\n",
       "      <td>2.147484e+09</td>\n",
       "      <td>6.329811e+08</td>\n",
       "      <td>2.147484e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>2.147484e+15</td>\n",
       "      <td>1.591000e+09</td>\n",
       "      <td>2.147484e+09</td>\n",
       "      <td>2.147484e+09</td>\n",
       "      <td>1.057350e+09</td>\n",
       "      <td>2.147484e+09</td>\n",
       "      <td>1.093915e+09</td>\n",
       "      <td>1.040540e+09</td>\n",
       "      <td>1.935943e+09</td>\n",
       "      <td>1.030014e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3.796047e+07</td>\n",
       "      <td>1.404940e+07</td>\n",
       "      <td>4.454265e+07</td>\n",
       "      <td>3.520902e+07</td>\n",
       "      <td>1.442925e+07</td>\n",
       "      <td>2.777879e+07</td>\n",
       "      <td>5.240247e+07</td>\n",
       "      <td>6.491862e+06</td>\n",
       "      <td>6.121142e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>4.439013e+13</td>\n",
       "      <td>1.149918e+07</td>\n",
       "      <td>1.482155e+07</td>\n",
       "      <td>3.352061e+07</td>\n",
       "      <td>1.806197e+07</td>\n",
       "      <td>3.346105e+07</td>\n",
       "      <td>9.841849e+06</td>\n",
       "      <td>7.763925e+06</td>\n",
       "      <td>2.102546e+07</td>\n",
       "      <td>7.787572e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            date_cloture_exercice  CJCK_TotalActifBrut  EG_ImpotsTaxes  \\\n",
       "count                       29960         2.996000e+04    2.996000e+04   \n",
       "mean   2017-11-29 11:45:23.311000         3.700343e+06    1.221733e+06   \n",
       "min           2017-01-01 00:00:00        -6.641700e+05   -1.256488e+06   \n",
       "25%           2017-12-31 00:00:00         1.204178e+05    0.000000e+00   \n",
       "50%           2017-12-31 00:00:00         4.494340e+05    1.141165e+05   \n",
       "75%           2017-12-31 00:00:00         1.374461e+06    5.371698e+05   \n",
       "max           2017-12-31 00:00:00         2.147484e+09    1.507690e+09   \n",
       "std                           NaN         3.796047e+07    1.404940e+07   \n",
       "\n",
       "       FJ_ResultatFinancier  FA_ChiffreAffairesVentes  HN_RésultatNet  \\\n",
       "count          2.996000e+04              2.996000e+04    2.996000e+04   \n",
       "mean           4.084171e+06              1.882187e+06    3.071768e+05   \n",
       "min           -1.139370e+06             -7.865800e+04   -2.818639e+08   \n",
       "25%            0.000000e+00              0.000000e+00    0.000000e+00   \n",
       "50%            1.455500e+05              0.000000e+00    6.111000e+03   \n",
       "75%            1.112943e+06              0.000000e+00    7.339325e+04   \n",
       "max            2.147484e+09              2.147484e+09    1.924000e+09   \n",
       "std            4.454265e+07              3.520902e+07    1.442925e+07   \n",
       "\n",
       "       DA_TresorerieActive  DL_DettesCourtTerme  FB_AchatsMarchandises  \\\n",
       "count         2.996000e+04         2.996000e+04           2.996000e+04   \n",
       "mean          1.384349e+06         3.183492e+06           2.092675e+05   \n",
       "min          -2.147319e+09        -2.147474e+09          -1.119060e+05   \n",
       "25%           7.622000e+03         3.809925e+04           0.000000e+00   \n",
       "50%           3.050000e+04         2.417745e+05           0.000000e+00   \n",
       "75%           1.524000e+05         8.233588e+05           0.000000e+00   \n",
       "max           1.564155e+09         2.147484e+09           6.329811e+08   \n",
       "std           2.777879e+07         5.240247e+07           6.491862e+06   \n",
       "\n",
       "       FR_ResultatExceptionnel  ...  ratio_resultat_exceptionnel  \\\n",
       "count             2.996000e+04  ...                 2.996000e+04   \n",
       "mean              6.233579e+06  ...                 3.227332e+12   \n",
       "min              -1.832627e+09  ...                -1.248038e+15   \n",
       "25%               0.000000e+00  ...                 0.000000e+00   \n",
       "50%               2.852920e+05  ...                 1.922000e+09   \n",
       "75%               1.515148e+06  ...                 5.235205e+11   \n",
       "max               2.147484e+09  ...                 2.147484e+15   \n",
       "std               6.121142e+07  ...                 4.439013e+13   \n",
       "\n",
       "       cible_HN_RésultatNet_T_plus_1  ResultatNet_T_moins_1  CA_T_moins_1  \\\n",
       "count                   2.996000e+04           2.996000e+04  2.996000e+04   \n",
       "mean                    3.178510e+05           2.820253e+05  1.834384e+06   \n",
       "min                    -2.675530e+08          -9.694030e+08 -5.430000e+05   \n",
       "25%                     0.000000e+00           0.000000e+00  0.000000e+00   \n",
       "50%                     3.582500e+03           7.237000e+03  0.000000e+00   \n",
       "75%                     6.986175e+04           6.980450e+04  5.150000e+01   \n",
       "max                     1.591000e+09           2.147484e+09  2.147484e+09   \n",
       "std                     1.149918e+07           1.482155e+07  3.352061e+07   \n",
       "\n",
       "       ResultatNet_T_moins_2  CA_T_moins_2  delta_ResultatNet_1an  \\\n",
       "count           2.996000e+04  2.996000e+04           2.996000e+04   \n",
       "mean            9.066098e+04  1.839003e+06           2.515151e+04   \n",
       "min            -1.855684e+09 -7.975916e+06          -5.564057e+08   \n",
       "25%            -1.135750e+03  0.000000e+00          -1.705950e+04   \n",
       "50%             1.048400e+04  0.000000e+00           0.000000e+00   \n",
       "75%             7.254275e+04  1.006725e+04           2.494800e+04   \n",
       "max             1.057350e+09  2.147484e+09           1.093915e+09   \n",
       "std             1.806197e+07  3.346105e+07           9.841849e+06   \n",
       "\n",
       "       delta_CA_1an  delta_ResultatNet_2ans  delta_CA_2ans  \n",
       "count  2.996000e+04            2.996000e+04   2.996000e+04  \n",
       "mean   4.780360e+04            2.165158e+05   4.318455e+04  \n",
       "min   -3.036511e+08           -1.062435e+09  -2.538310e+08  \n",
       "25%    0.000000e+00           -2.933825e+04   0.000000e+00  \n",
       "50%    0.000000e+00            0.000000e+00   0.000000e+00  \n",
       "75%    0.000000e+00            3.827300e+04   0.000000e+00  \n",
       "max    1.040540e+09            1.935943e+09   1.030014e+09  \n",
       "std    7.763925e+06            2.102546e+07   7.787572e+06  \n",
       "\n",
       "[8 rows x 29 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ml_pd.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Démarrage de l'Entraînement Profond (Modèle Génie) ---\n",
      "\n",
      "=============================================\n",
      "✅ Modèle Final Entraîné (Modèle Monstre XGBoost)\n",
      "TEMPS D'ENTRAÎNEMENT RÉEL : 23.13 secondes\n",
      "  (Ce temps est le minimum pour 1000 arbres)\n",
      "  > MAE (Moyenne 5-Fold CV) : 600,246.20\n",
      "  > RMSE (Moyenne 5-Fold CV) : 10,050,285.38\n",
      "=============================================\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import time\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, make_scorer\n",
    "\n",
    "# Configuration et fonctions (omises ici pour la concision)\n",
    "\n",
    "# --- NOUVEAUX PARAMÈTRES POUR FORCER UN APPRENTISSAGE PROFOND ---\n",
    "# Ces paramètres vont créer un modèle beaucoup plus lourd et précis.\n",
    "N_ESTIMATORS_FINAL = 1000\n",
    "MAX_DEPTH_FINAL = 8 \n",
    "\n",
    "# --- 1. CHARGEMENT ET PRÉPARATION DES DONNÉES (Identique) ---\n",
    "FILE_PATH_ML = \"../Data/processed/sirene_bilan_ML_prets.parquet\" \n",
    "cible_col = \"cible_HN_RésultatNet_T_plus_1\"\n",
    "\n",
    "# [Code de chargement et de définition des ensembles X_full, Y_full, FEATURES_DELTAS]\n",
    "# ... (Assurez-vous que ces variables sont bien définies dans votre notebook) ...\n",
    "\n",
    "# Préparation X et Y (Conversion des types pour la robustesse numérique)\n",
    "df_ml = pl.read_parquet(FILE_PATH_ML)\n",
    "df_ml_pd = df_ml.to_pandas()\n",
    "Y_full = df_ml_pd[cible_col].astype(np.float64) \n",
    "X_full = df_ml_pd[[col for col in FEATURES_DELTAS if col in df_ml_pd.columns]].fillna(0).astype(np.float64)\n",
    "\n",
    "\n",
    "# --- 2. PIPELINE DE MODÉLISATION (Modèle 'Monstre') ---\n",
    "print(\"--- Démarrage de l'Entraînement Profond (Modèle Génie) ---\")\n",
    "start_time = time.time()\n",
    "\n",
    "# Définition du pré-traitement (StandardScaler)\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[('num', StandardScaler(), FEATURES_DELTAS)],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "# Modèle XGBoost avec des paramètres maximisés\n",
    "model_xgb_monstre = xgb.XGBRegressor(\n",
    "    n_estimators=N_ESTIMATORS_FINAL,        # 5x plus d'arbres\n",
    "    max_depth=MAX_DEPTH_FINAL,              # Arbres plus complexes\n",
    "    learning_rate=0.03,                     # Taux d'apprentissage très fin\n",
    "    random_state=42, \n",
    "    n_jobs=-1,\n",
    "    objective='reg:squarederror'\n",
    ")\n",
    "\n",
    "# Pipeline complet\n",
    "pipeline_monstre = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', model_xgb_monstre)\n",
    "])\n",
    "\n",
    "# --- 3. ÉVALUATION FINALE (5-Fold CV) ---\n",
    "rmse_scores = cross_val_score(pipeline_monstre, X_full, Y_full, scoring=scorer_rmse, cv=kf)\n",
    "mae_scores = cross_val_score(pipeline_monstre, X_full, Y_full, scoring=scorer_mae, cv=kf)\n",
    "\n",
    "end_time = time.time()\n",
    "training_time = end_time - start_time\n",
    "\n",
    "# Calcul des moyennes finales\n",
    "rmse_cv_mean = np.mean(rmse_scores) * -1\n",
    "mae_cv_mean = np.mean(mae_scores) * -1\n",
    "\n",
    "print(\"\\n=============================================\")\n",
    "print(\"✅ Modèle Final Entraîné (Modèle Monstre XGBoost)\")\n",
    "print(f\"TEMPS D'ENTRAÎNEMENT RÉEL : {training_time:.2f} secondes\")\n",
    "print(f\"  (Ce temps est le minimum pour {N_ESTIMATORS_FINAL} arbres)\")\n",
    "print(f\"  > MAE (Moyenne 5-Fold CV) : {mae_cv_mean:,.2f}\")\n",
    "print(f\"  > RMSE (Moyenne 5-Fold CV) : {rmse_cv_mean:,.2f}\")\n",
    "print(\"=============================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- DÉMARRAGE DE L'OPTIMISATION PAR GRILLE (LE MONSTRE APPREND) ---\n",
      "Nombre de modèles à tester : 40 fits.\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot have number of splits n_splits=5 greater than the number of samples: n_samples=0.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 90\u001b[39m\n\u001b[32m     87\u001b[39m start_time = time.time()\n\u001b[32m     89\u001b[39m \u001b[38;5;66;03m# Entraînement sur la cible ARCSINH-TRANSFORMÉE\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m90\u001b[39m \u001b[43mgrid_search\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_full\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_full_arcsinh\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     92\u001b[39m end_time = time.time()\n\u001b[32m     93\u001b[39m training_time = end_time - start_time\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Cours/Master/Cours/M1/Supervised Learning/Final Project/.venv/lib/python3.14/site-packages/sklearn/base.py:1365\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1358\u001b[39m     estimator._validate_params()\n\u001b[32m   1360\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1361\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1362\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1363\u001b[39m     )\n\u001b[32m   1364\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1365\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Cours/Master/Cours/M1/Supervised Learning/Final Project/.venv/lib/python3.14/site-packages/sklearn/model_selection/_search.py:1051\u001b[39m, in \u001b[36mBaseSearchCV.fit\u001b[39m\u001b[34m(self, X, y, **params)\u001b[39m\n\u001b[32m   1045\u001b[39m     results = \u001b[38;5;28mself\u001b[39m._format_results(\n\u001b[32m   1046\u001b[39m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[32m   1047\u001b[39m     )\n\u001b[32m   1049\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[32m-> \u001b[39m\u001b[32m1051\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1053\u001b[39m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[32m   1054\u001b[39m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[32m   1055\u001b[39m first_test_score = all_out[\u001b[32m0\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mtest_scores\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Cours/Master/Cours/M1/Supervised Learning/Final Project/.venv/lib/python3.14/site-packages/sklearn/model_selection/_search.py:1605\u001b[39m, in \u001b[36mGridSearchCV._run_search\u001b[39m\u001b[34m(self, evaluate_candidates)\u001b[39m\n\u001b[32m   1603\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[32m   1604\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1605\u001b[39m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Cours/Master/Cours/M1/Supervised Learning/Final Project/.venv/lib/python3.14/site-packages/sklearn/model_selection/_search.py:1009\u001b[39m, in \u001b[36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[39m\u001b[34m(candidate_params, cv, more_results)\u001b[39m\n\u001b[32m    989\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.verbose > \u001b[32m0\u001b[39m:\n\u001b[32m    990\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[32m    991\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[33m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[33m candidates,\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    992\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[33m fits\u001b[39m\u001b[33m\"\u001b[39m.format(\n\u001b[32m    993\u001b[39m             n_splits, n_candidates, n_candidates * n_splits\n\u001b[32m    994\u001b[39m         )\n\u001b[32m    995\u001b[39m     )\n\u001b[32m    997\u001b[39m out = parallel(\n\u001b[32m    998\u001b[39m     delayed(_fit_and_score)(\n\u001b[32m    999\u001b[39m         clone(base_estimator),\n\u001b[32m   1000\u001b[39m         X,\n\u001b[32m   1001\u001b[39m         y,\n\u001b[32m   1002\u001b[39m         train=train,\n\u001b[32m   1003\u001b[39m         test=test,\n\u001b[32m   1004\u001b[39m         parameters=parameters,\n\u001b[32m   1005\u001b[39m         split_progress=(split_idx, n_splits),\n\u001b[32m   1006\u001b[39m         candidate_progress=(cand_idx, n_candidates),\n\u001b[32m   1007\u001b[39m         **fit_and_score_kwargs,\n\u001b[32m   1008\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1009\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[38;5;129;01min\u001b[39;00m \u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1010\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1011\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplitter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1012\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1013\u001b[39m )\n\u001b[32m   1015\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) < \u001b[32m1\u001b[39m:\n\u001b[32m   1016\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1017\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mNo fits were performed. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1018\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWas the CV iterator empty? \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1019\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWere there no candidates?\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1020\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Cours/Master/Cours/M1/Supervised Learning/Final Project/.venv/lib/python3.14/site-packages/sklearn/model_selection/_split.py:404\u001b[39m, in \u001b[36m_BaseKFold.split\u001b[39m\u001b[34m(self, X, y, groups)\u001b[39m\n\u001b[32m    402\u001b[39m n_samples = _num_samples(X)\n\u001b[32m    403\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.n_splits > n_samples:\n\u001b[32m--> \u001b[39m\u001b[32m404\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    405\u001b[39m         (\n\u001b[32m    406\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mCannot have number of splits n_splits=\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[33m greater\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    407\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33m than the number of samples: n_samples=\u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    408\u001b[39m         ).format(\u001b[38;5;28mself\u001b[39m.n_splits, n_samples)\n\u001b[32m    409\u001b[39m     )\n\u001b[32m    411\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m train, test \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().split(X, y, groups):\n\u001b[32m    412\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m train, test\n",
      "\u001b[31mValueError\u001b[39m: Cannot have number of splits n_splits=5 greater than the number of samples: n_samples=0."
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import time\n",
    "from sklearn.model_selection import KFold, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, make_scorer\n",
    "\n",
    "# --- 0. DÉFINITION GLOBALE DES FONCTIONS ROBUSTES (CORRIGÉES) ---\n",
    "\n",
    "# Fonction de transformation robuste de la cible (ARCSINH STANDARD)\n",
    "def arcsinh_transform_safe(y):\n",
    "    # Utilisation directe de np.arcsinh(y) pour la stabilité sur les grandes valeurs et les négatifs.\n",
    "    # On ajoute np.finfo(float).eps pour assurer la robustesse près de zéro avant transformation.\n",
    "    return np.arcsinh(y + np.finfo(float).eps)\n",
    "\n",
    "# Fonction d'inverse transformation\n",
    "def inv_arcsinh_transform_safe(y_pred_arcsinh):\n",
    "    # Inverse de arcsinh : np.sinh(x)\n",
    "    return np.sinh(y_pred_arcsinh) - np.finfo(float).eps\n",
    "\n",
    "scorer_mae = make_scorer(mean_absolute_error, greater_is_better=False)\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# --- 1. CHARGEMENT ET PRÉPARATION (Application de la transformation arcsinh SÛRE) ---\n",
    "FILE_PATH_ML = \"../Data/processed/sirene_bilan_ML_prets.parquet\" \n",
    "cible_col = \"cible_HN_RésultatNet_T_plus_1\"\n",
    "\n",
    "try:\n",
    "    df_ml = pl.read_parquet(FILE_PATH_ML)\n",
    "except Exception:\n",
    "    raise RuntimeError(\"Erreur de chargement du Parquet. Vérifiez le chemin.\")\n",
    "\n",
    "df_ml_pd = df_ml.to_pandas()\n",
    "\n",
    "# Application de la transformation ARCSINH SÛRE à la Cible (Y)\n",
    "Y_full_arcsinh = arcsinh_transform_safe(df_ml_pd[cible_col].astype(np.float64))\n",
    "\n",
    "# Définition des Features (Ratios T + Deltas T-1)\n",
    "FEATURES_FINALES = [\n",
    "    'ratio_rentabilite_nette', 'ratio_endettement', 'ratio_marge_brute', \n",
    "    'HN_RésultatNet', 'FA_ChiffreAffairesVentes', \n",
    "    'delta_ResultatNet_1an', 'delta_CA_1an', 'ResultatNet_T_moins_1', 'CA_T_moins_1'\n",
    "]\n",
    "X_full = df_ml_pd[FEATURES_FINALES].fillna(0).astype(np.float64) \n",
    "\n",
    "\n",
    "# --- 2. DÉFINITION DU PIPELINE ET GRIDSEARCH ---\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[('num', StandardScaler(), FEATURES_FINALES)],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "model_xgb = xgb.XGBRegressor(\n",
    "    random_state=42, n_jobs=-1, objective='reg:squarederror'\n",
    ")\n",
    "\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', model_xgb)\n",
    "])\n",
    "\n",
    "# Grille d'hyperparamètres (Conçue pour prendre du temps)\n",
    "param_grid = {\n",
    "    'regressor__n_estimators': [500, 1000],  \n",
    "    'regressor__max_depth': [6, 10],        \n",
    "    'regressor__learning_rate': [0.03, 0.05] \n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=pipeline,\n",
    "    param_grid=param_grid,\n",
    "    scoring=scorer_mae,\n",
    "    cv=kf,\n",
    "    verbose=2,\n",
    "    n_jobs=-1  \n",
    ")\n",
    "\n",
    "\n",
    "# --- 3. EXÉCUTION DE L'ENTRAÎNEMENT (LE LONG PROCESSUS) ---\n",
    "print(\"\\n--- DÉMARRAGE DE L'OPTIMISATION PAR GRILLE (LE MONSTRE APPREND) ---\")\n",
    "print(f\"Nombre de modèles à tester : {len(param_grid['regressor__n_estimators']) * len(param_grid['regressor__max_depth']) * len(param_grid['regressor__learning_rate']) * kf.get_n_splits()} fits.\")\n",
    "start_time = time.time()\n",
    "\n",
    "# Entraînement sur la cible ARCSINH-TRANSFORMÉE\n",
    "grid_search.fit(X_full, Y_full_arcsinh)\n",
    "\n",
    "end_time = time.time()\n",
    "training_time = end_time - start_time\n",
    "\n",
    "\n",
    "# --- 4. ÉVALUATION FINALE ET INVERSE-TRANSFORMATION ---\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Prédiction sur l'ensemble complet (Arcsih-transformé)\n",
    "Y_pred_arcsinh = best_model.predict(X_full)\n",
    "\n",
    "# Inverse Transformation des résultats\n",
    "Y_pred_final_unscaled = inv_arcsinh_transform_safe(Y_pred_arcsinh)\n",
    "Y_true_unscaled = inv_arcsinh_transform_safe(Y_full_arcsinh)\n",
    "\n",
    "# Calcul des métriques sur les valeurs ORIGINALES\n",
    "final_mae = mean_absolute_error(Y_true_unscaled, Y_pred_final_unscaled)\n",
    "final_rmse = root_mean_squared_error(Y_true_unscaled, Y_pred_final_unscaled)\n",
    "\n",
    "\n",
    "print(\"\\n=============================================\")\n",
    "print(\"🏆 MODÈLE MONSTRE FINAL : RÉSULTATS\")\n",
    "print(f\"TEMPS TOTAL D'OPTIMISATION : {training_time/60:.2f} minutes\")\n",
    "print(f\"MEILLEURS HYPERPARAMÈTRES : {grid_search.best_params_}\")\n",
    "print(\"-\" * 45)\n",
    "print(f\"  > MAE FINAL (Erreur Absolue Moyenne) : {final_mae:,.2f}\")\n",
    "print(f\"  > RMSE FINAL : {final_rmse:,.2f}\")\n",
    "print(\"=============================================\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
